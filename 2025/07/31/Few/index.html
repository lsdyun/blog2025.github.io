<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="/blog2025.github.io/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog2025.github.io/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog2025.github.io/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog2025.github.io/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog2025.github.io/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css" integrity="sha256-dABdfBfUoC8vJUBOwGVdm8L9qlMWaHTIfXt+7GnZCIo=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"lsdyun.github.io","root":"/blog2025.github.io/","images":"/blog2025.github.io/images","scheme":"Pisces","darkmode":false,"version":"8.22.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"duration":200,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/blog2025.github.io/search.xml","localsearch":{"enable":true,"top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/blog2025.github.io/js/config.js"></script>

    <meta name="description" content="Few-Shot少样本图像分类算法总结（含代码链接） Few-shot learning 基础Supervised learning 和 Few-shot learning supervised learning 一种使用带标签数据集训练模型的方法，其中输入数据与对应的输出标签（即“监督信号”）配对。 训练集通常规模大、覆盖所有目标类别，确保测试样本的类别已包含在训练中，从而实现良好泛化‌。 例如">
<meta property="og:type" content="article">
<meta property="og:title" content="小样本训练">
<meta property="og:url" content="https://lsdyun.github.io/blog2025.github.io/2025/07/31/Few/index.html">
<meta property="og:site_name" content="记录博客">
<meta property="og:description" content="Few-Shot少样本图像分类算法总结（含代码链接） Few-shot learning 基础Supervised learning 和 Few-shot learning supervised learning 一种使用带标签数据集训练模型的方法，其中输入数据与对应的输出标签（即“监督信号”）配对。 训练集通常规模大、覆盖所有目标类别，确保测试样本的类别已包含在训练中，从而实现良好泛化‌。 例如">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://lsdyun.github.io/blog2025.github.io/2025/05/28/Ajax%20+%20axios/mermaid_20250731_bac117.png">
<meta property="article:published_time" content="2025-07-31T02:35:58.329Z">
<meta property="article:modified_time" content="2025-07-31T02:39:25.419Z">
<meta property="article:author" content="lsdyun">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://lsdyun.github.io/blog2025.github.io/2025/05/28/Ajax%20+%20axios/mermaid_20250731_bac117.png">


<link rel="canonical" href="https://lsdyun.github.io/blog2025.github.io/2025/07/31/Few/">


<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://lsdyun.github.io/blog2025.github.io/2025/07/31/Few/","path":"2025/07/31/Few/","title":"小样本训练"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>小样本训练 | 记录博客</title>
  








  <noscript>
    <link rel="stylesheet" href="/blog2025.github.io/css/noscript.css">
  </noscript>
<style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style></head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog2025.github.io/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">记录博客</p>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/blog2025.github.io/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/blog2025.github.io/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-categories"><a href="/blog2025.github.io/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/blog2025.github.io/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
      <div class="search-header">
        <span class="search-icon">
          <i class="fa fa-search"></i>
        </span>
        <div class="search-input-container">
          <input autocomplete="off" autocapitalize="off" maxlength="80"
                placeholder="搜索..." spellcheck="false"
                type="search" class="search-input">
        </div>
        <span class="popup-btn-close" role="button">
          <i class="fa fa-times-circle"></i>
        </span>
      </div>
      <div class="search-result-container">
        <div class="search-result-icon">
          <i class="fa fa-spinner fa-pulse fa-5x"></i>
        </div>
      </div>
    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80"><span class="nav-number">1.</span> <span class="nav-text">基础</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Supervised-learning-%E5%92%8C-Few-shot-learning"><span class="nav-number">1.1.</span> <span class="nav-text">Supervised learning 和 Few-shot learning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Few-shot-learning"><span class="nav-number">1.2.</span> <span class="nav-text">Few-shot learning</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#sicara-easy-few-shot-learning"><span class="nav-number">2.</span> <span class="nav-text">sicara&#x2F;easy-few-shot-learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#15%E5%88%86%E9%92%9F%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B"><span class="nav-number">2.1.</span> <span class="nav-text">15分钟快速上手</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5"><span class="nav-number">2.1.1.</span> <span class="nav-text">基础概念</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%8E%9F%E5%9E%8B%E7%BD%91%E7%BB%9C-%E6%A0%B8%E5%BF%83"><span class="nav-number">2.1.2.</span> <span class="nav-text">原型网络(核心)</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="nav-number">2.1.2.1.</span> <span class="nav-text">工作原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E7%8E%B0%E6%AD%A5%E9%AA%A4"><span class="nav-number">2.1.2.2.</span> <span class="nav-text">实现步骤</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E9%97%AE%E9%A2%98"><span class="nav-number">2.1.2.3.</span> <span class="nav-text">问题</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B"><span class="nav-number">2.1.3.</span> <span class="nav-text">完整代码实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Train-a-model-with-Episodic-Training"><span class="nav-number">2.2.</span> <span class="nav-text">Train a model with Episodic Training</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%85%A5%E9%97%A8%EF%BC%9A"><span class="nav-number">2.2.1.</span> <span class="nav-text">入门：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%EF%BC%9A"><span class="nav-number">2.2.2.</span> <span class="nav-text">训练：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%EF%BC%9A"><span class="nav-number">2.2.3.</span> <span class="nav-text">评估：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B-1"><span class="nav-number">2.2.4.</span> <span class="nav-text">完整代码实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Train-a-model-with-Classical-Training"><span class="nav-number">2.3.</span> <span class="nav-text">Train a model with Classical Training</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%BC%80%E5%A7%8B%EF%BC%9A"><span class="nav-number">2.3.1.</span> <span class="nav-text">开始：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AE%AD%E7%BB%83%EF%BC%9A-1"><span class="nav-number">2.3.2.</span> <span class="nav-text">训练：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E8%AF%84%E4%BC%B0%EF%BC%9A-1"><span class="nav-number">2.3.3.</span> <span class="nav-text">评估：</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%E5%AE%9E%E4%BE%8B-2"><span class="nav-number">2.3.4.</span> <span class="nav-text">完整代码实例</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Episodic-vs-Classical"><span class="nav-number">2.4.</span> <span class="nav-text">Episodic vs Classical</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="lsdyun"
      src="/blog2025.github.io/images/avatar.png">
  <p class="site-author-name" itemprop="name">lsdyun</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/blog2025.github.io/archives/">
          <span class="site-state-item-count">38</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/blog2025.github.io/categories/">
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/lsdyun" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lsdyun" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://lsdyun.github.io/blog2025.github.io/2025/07/31/Few/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog2025.github.io/images/avatar.png">
      <meta itemprop="name" content="lsdyun">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="记录博客">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="小样本训练 | 记录博客">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          小样本训练
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2025-07-31 10:35:58 / 修改时间：10:39:25" itemprop="dateCreated datePublished" datetime="2025-07-31T10:35:58+08:00">2025-07-31</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/blog2025.github.io/categories/Few-shot-learning/" itemprop="url" rel="index"><span itemprop="name">Few-shot learning</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv">
      <span class="post-meta-item-icon">
        <i class="far fa-eye"></i>
      </span>
      <span class="post-meta-item-text">阅读次数：</span>
      <span id="busuanzi_value_page_pv"></span>
    </span>
</div>


		<!--  设置置顶图标  -->
		        
		<!--  设置置顶图标  -->
        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p><a target="_blank" rel="noopener" href="https://blog.csdn.net/A15216110998/article/details/144417167">Few-Shot少样本图像分类算法总结（含代码链接）</a></p>
<p><a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_44211968/article/details/121314757">Few-shot learning</a></p>
<h1 id="基础"><a href="#基础" class="headerlink" title="基础"></a>基础</h1><h2 id="Supervised-learning-和-Few-shot-learning"><a href="#Supervised-learning-和-Few-shot-learning" class="headerlink" title="Supervised learning 和 Few-shot learning"></a><strong>Supervised learning</strong> 和 <strong>Few-shot learning</strong></h2><ul>
<li><p><strong>supervised learning</strong></p>
<p>一种使用带标签数据集训练模型的方法，其中输入数据与对应的输出标签（即“监督信号”）配对。</p>
<p>训练集通常规模大、覆盖所有目标类别，确保测试样本的类别已包含在训练中，从而实现良好泛化‌。</p>
<p>例如，在猫狗图像分类任务中，训练集包含大量猫和狗的带标签图片；测试时，模型能预测新猫狗图片的类别，因为这些类别已在训练中出现过‌。</p>
</li>
<li><p><strong>Few-shot learning</strong></p>
<p>少样本学习专注于在目标类别仅有极少量标注样本（如5个或更少）时，模型快速适应新任务。</p>
<p>它通常依赖元学习（meta-learning）或相似度度量方法，利用**“支撑集”（support set）<strong>提供少量示例来辅助预测</strong>“查询样本”（query sample）**。</p>
<p>查询样本类别通常是未知的（未在训练中出现），模型通过支撑集建立新类别的泛化能力‌。</p>
<p>例如，在医疗诊断中，训练模型可能只见过少数罕见病例样本；测试时，给定一个新病例（查询样本），模型需基于支撑集的少量示例识别其类别‌</p>
</li>
</ul>
<table>
<thead>
<tr>
<th></th>
<th>Supervised learning（监督学习）</th>
<th>Few-shot learning（少样本学习）</th>
</tr>
</thead>
<tbody><tr>
<td>情景一</td>
<td>测试样本之前从未见过**（类别已知，实例未知）**</td>
<td>query（查询）的样本之前从未见过**（类别可能未知或新出现‌）**</td>
</tr>
<tr>
<td>情景二</td>
<td>测试样本类别出现在训练集中**（类别已知，无需新类别适应）**</td>
<td>query 的样本来自于未知类别**（明确类别未知）**</td>
</tr>
</tbody></table>
<hr>
<h2 id="Few-shot-learning"><a href="#Few-shot-learning" class="headerlink" title="Few-shot learning"></a>Few-shot learning</h2><ol>
<li><p><strong>Few-shot learning</strong> 不是让模型去认识具体哪个东西，比如老虎，大象（小）。而是让模型分清物种（大），区别样本的物种不同。</p>
</li>
<li><p><strong>Datasets（数据集）</strong></p>
<ul>
<li><p><strong>training set（训练集）</strong>：</p>
<p>样本量很大，训练出来的模型在测试集能取得很好的泛化效果。</p>
<blockquote>
<p>应用场景：大规模分类（如ImageNet图像训练）。</p>
</blockquote>
</li>
<li><p><strong>support set（支撑组）</strong>：</p>
<p>小样本带标签的数据集。数据样本很少，不足以训练一个神经网络。</p>
<blockquote>
<p>应用场景：小样本学习（如 Few-shot 分类任务）</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>支撑组通常依赖于预训练模型（用大规模训练集得出）。</p>
<p>没有训练集建立的初始模型，支撑组无法有效发挥作用；</p>
<p>反之，训练集的泛化效果可在支撑组上验证其在小样本环境中的鲁棒性‌（<strong>系统抵抗故障和干扰的能力</strong>）</p>
</blockquote>
<p><strong>实际应用顺序‌：</strong></p>
<ul>
<li>先使用训练集训练模型（调整参数）。</li>
<li>再用支撑组（或类似验证集）进行小样本测试或微调超参数。</li>
<li>最终通过独立测试集评估整体性能‌。</li>
</ul>
</li>
<li><p><strong>k-way</strong>： <strong>support set（支撑组）</strong> 中有 k 个类别</p>
<p><strong>n-shot</strong>： 每个类别有 n 个样本</p>
<p>示例： 4 个类别，每个类别分别有 2 个样本：<strong>4-way 2-shot support set</strong></p>
<table>
<thead>
<tr>
<th>兔子</th>
<th>老虎</th>
<th>松鼠</th>
<th>狐狸</th>
</tr>
</thead>
<tbody><tr>
<td>兔子1</td>
<td>老虎1</td>
<td>松鼠1</td>
<td>狐狸1</td>
</tr>
<tr>
<td>兔子2</td>
<td>老虎2</td>
<td>松鼠2</td>
<td>狐狸2</td>
</tr>
</tbody></table>
<p><strong>Few-shot learning</strong> 的预测<strong>准确率</strong>随 **way（类别）**的增加而减小，随 **shot（样本）**的增加而增加。</p>
<blockquote>
<p>类别越多样本减少，导致效果越差，</p>
<p>类别越少样本增多，反而效果很好。</p>
</blockquote>
</li>
<li><p><strong>Few-shot learning</strong> 的基本思想：</p>
<p>采用一个<strong>相似性函数</strong>来度量样本和的相似性。</p>
<ul>
<li>值越大，表明 **query（查询）**的图片和 **support set（支撑组）**的图片越相似。</li>
<li>值越小，表明 **query（查询）**的图片和 **support set（支撑组）**的图片差距越大。</li>
</ul>
</li>
</ol>
<hr>
<h1 id="sicara-easy-few-shot-learning"><a href="#sicara-easy-few-shot-learning" class="headerlink" title="sicara&#x2F;easy-few-shot-learning"></a><a href="sicara/easy-few-shot-learning">sicara&#x2F;easy-few-shot-learning</a></h1><h2 id="15分钟快速上手"><a href="#15分钟快速上手" class="headerlink" title="15分钟快速上手"></a>15分钟快速上手</h2><h3 id="基础概念"><a href="#基础概念" class="headerlink" title="基础概念"></a>基础概念</h3><ul>
<li><strong>支持集(Support Set)</strong>：少量标注样本（如5类×5张图）</li>
<li><strong>查询集(Query Set)</strong>：需要分类的新样本</li>
<li><strong>任务(Task)</strong>：一次完整的分类挑战（支持集+查询集）</li>
</ul>
<h3 id="原型网络-核心"><a href="#原型网络-核心" class="headerlink" title="原型网络(核心)"></a>原型网络(核心)</h3><p><em>Prototypical Networks</em></p>
<h4 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h4><ul>
<li><p>**特征提取：**用预训练CNN（如ResNet18）把照片变成数字向量（512个数字）</p>
<p>例：金毛照片 → [0.2, -1.3, 0.8,…] (512个特征值)</p>
</li>
<li><p>**计算原型：**对每个类，计算它所有照片特征的平均值</p>
<p>例：金毛原型 &#x3D; (金毛特征1 + 金毛特征2 + …) &#x2F; 5</p>
</li>
<li><p>**距离比较：**计算查询图片与每个原型的距离</p>
</li>
<li><p>**分类决策：**选择距离最近的类别</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">分类结果 = argmin(||查询特征 - 类原型||²)</span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[支持集图片] --&gt; B[特征提取器] </span><br><span class="line">B --&gt; C&#123;计算每个类的原型&#125; </span><br><span class="line">D[查询集图片] --&gt; B</span><br><span class="line">C --&gt; E[比较距离]</span><br><span class="line">E --&gt; F[分类结果]</span><br></pre></td></tr></table></figure>

<h4 id="实现步骤"><a href="#实现步骤" class="headerlink" title="实现步骤"></a>实现步骤</h4><ol>
<li><p>准备环境</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">!pip install easyfsl  <span class="comment"># 安装小样本学习库</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms, models</span><br><span class="line"><span class="keyword">from</span> easyfsl.samplers <span class="keyword">import</span> TaskSampler  <span class="comment"># 关键：任务生成器</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>加载数据集</p>
<p>使用 Omniglot 数据集（手写字符集）</p>
<ul>
<li><p>包含1623个字符，每个字符有20种不同写法</p>
</li>
<li><p>关键处理：将黑白图转成3通道（适配预训练模型）</p>
</li>
<li><p>分为训练集（背景集）和测试集（评估集）</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 图像预处理（适配预训练模型）</span></span><br><span class="line"><span class="comment"># 注意：background=True 选择训练集，background=False 选择测试集</span></span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">     <span class="comment"># Omniglot 图像是单通道的，但我们的模型期望 3 通道图像</span></span><br><span class="line">    transforms.Grayscale(num_output_channels=<span class="number">3</span>),  <span class="comment"># 单通道→三通道</span></span><br><span class="line">    transforms.Resize(<span class="number">28</span>),</span><br><span class="line">    transforms.ToTensor()</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">train_set = Omniglot(root=<span class="string">&quot;./data&quot;</span>, background=<span class="literal">True</span>, transform=transform, download=<span class="literal">True</span>)</span><br><span class="line">test_set = Omniglot(root=<span class="string">&quot;./data&quot;</span>, background=<span class="literal">False</span>, transform=transform, download=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>构建模型（核心！）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">原型网络</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, 骨干网络</span>):</span><br><span class="line">        <span class="variable language_">self</span>.骨干网络 = 骨干网络  <span class="comment"># 使用ResNet18提取特征</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">分类</span>(<span class="params">self, 支持图, 支持标签, 查询图</span>):</span><br><span class="line">        <span class="comment"># 1. 提取特征</span></span><br><span class="line">        支持特征 = <span class="variable language_">self</span>.骨干网络(支持图)</span><br><span class="line">        查询特征 = <span class="variable language_">self</span>.骨干网络(查询图)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 计算每个类的原型中心</span></span><br><span class="line">        原型列表 = []</span><br><span class="line">        <span class="keyword">for</span> 类别 <span class="keyword">in</span> 所有类别:</span><br><span class="line">            该类特征 = 支持特征[支持标签==类别]</span><br><span class="line">            原型 = 该类特征.mean(<span class="number">0</span>)  <span class="comment"># 取平均值</span></span><br><span class="line">            原型列表.append(原型)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 计算查询图与每个原型的距离</span></span><br><span class="line">        距离矩阵 = torch.cdist(查询特征, 原型列表)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 距离越近得分越高（负距离）</span></span><br><span class="line">        <span class="keyword">return</span> -距离矩阵</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">PrototypicalNetworks</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, backbone</span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        <span class="variable language_">self</span>.backbone = backbone  <span class="comment"># 使用ResNet18</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, support_imgs, support_labels, query_imgs</span>):</span><br><span class="line">        <span class="comment"># 1. 特征提取</span></span><br><span class="line">        z_support = <span class="variable language_">self</span>.backbone(support_imgs)  <span class="comment"># 支持集特征 [25, 512]</span></span><br><span class="line">        z_query = <span class="variable language_">self</span>.backbone(query_imgs)      <span class="comment"># 查询集特征 [50, 512]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 2. 计算类原型（核心！）</span></span><br><span class="line">        n_way = <span class="built_in">len</span>(torch.unique(support_labels))  <span class="comment"># 类别数</span></span><br><span class="line">        prototypes = []</span><br><span class="line">        <span class="keyword">for</span> label <span class="keyword">in</span> <span class="built_in">range</span>(n_way):</span><br><span class="line">            <span class="comment"># 找到当前类的所有特征</span></span><br><span class="line">            class_features = z_support[support_labels == label]</span><br><span class="line">            <span class="comment"># 计算类原型：特征均值</span></span><br><span class="line">            prototypes.append(class_features.mean(dim=<span class="number">0</span>))</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 3. 拼接所有原型 [5, 512]</span></span><br><span class="line">        z_proto = torch.stack(prototypes) </span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 4. 计算欧氏距离</span></span><br><span class="line">        dists = torch.cdist(z_query, z_proto)  <span class="comment"># [50, 5]</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 5. 转换为分类得分（负距离）</span></span><br><span class="line">        <span class="keyword">return</span> -dists</span><br></pre></td></tr></table></figure>
</li>
<li><p>特殊数据加载器</p>
<p>普通数据加载器：每次给一批图片</p>
<p>小样本数据加载器：每次给一个完整任务</p>
<ul>
<li><p>包含5个类别（5-way）</p>
</li>
<li><p>每个类5张支持图+10张查询图（5-shot）</p>
</li>
<li><p>示例任务结构：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[类别A] 支持图1,2,3,4,5</span><br><span class="line">[类别B] 支持图1,2,3,4,5</span><br><span class="line">...</span><br><span class="line">[类别A] 查询图1,2,3...10</span><br><span class="line">[类别B] 查询图1,2,3...10</span><br></pre></td></tr></table></figure></li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 5-way 5-shot任务配置</span></span><br><span class="line">N_WAY = <span class="number">5</span>    <span class="comment"># 5个类别</span></span><br><span class="line">N_SHOT = <span class="number">5</span>   <span class="comment"># 每类5张支持图</span></span><br><span class="line">N_QUERY = <span class="number">10</span> <span class="comment"># 每类10张查询图</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建任务采样器</span></span><br><span class="line">test_sampler = TaskSampler(</span><br><span class="line">    test_set, </span><br><span class="line">    n_way=N_WAY, </span><br><span class="line">    n_shot=N_SHOT, </span><br><span class="line">    n_query=N_QUERY</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 任务数据加载器</span></span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_set,</span><br><span class="line">    batch_sampler=test_sampler,</span><br><span class="line">    collate_fn=test_sampler.episodic_collate_fn  <span class="comment"># 重组为任务结构</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li><p>评估与训练</p>
<ul>
<li><p>初始评估（使用ImageNet预训练模型）：</p>
<p>准确率 ≈ 86%</p>
<p>证明：即使没训练过，模型也能通过少量样本学习</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">model = PrototypicalNetworks(resnet18(pretrained=<span class="literal">True</span>)).cuda()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取一个任务</span></span><br><span class="line">(support, s_labels, query, q_labels, _) = <span class="built_in">next</span>(<span class="built_in">iter</span>(test_loader))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 预测</span></span><br><span class="line">scores = model(support.cuda(), s_labels.cuda(), query.cuda())</span><br><span class="line">predictions = scores.argmax(dim=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算准确率</span></span><br><span class="line">accuracy = (predictions == q_labels.cuda()).<span class="built_in">float</span>().mean()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;初始准确率: <span class="subst">&#123;accuracy.item()*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%&quot;</span>)  <span class="comment"># ≈86%</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>元学习训练：</p>
<p>在40,000个小样本任务上训练</p>
<p>每个任务都是新的分类挑战</p>
<p>训练后准确率 → 98%!</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 准备训练任务</span></span><br><span class="line">train_sampler = TaskSampler(train_set, n_way=<span class="number">5</span>, n_shot=<span class="number">5</span>, n_query=<span class="number">10</span>, n_tasks=<span class="number">40000</span>)</span><br><span class="line">train_loader = DataLoader(..., collate_fn=train_sampler.episodic_collate_fn)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 定义损失和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.Adam(model.parameters(), lr=<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 训练循环</span></span><br><span class="line"><span class="keyword">for</span> task <span class="keyword">in</span> train_loader:</span><br><span class="line">    support, s_labels, query, q_labels, _ = task</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    scores = model(support.cuda(), s_labels.cuda(), query.cuda())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss = criterion(scores, q_labels.cuda())</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 重新评估测试集</span></span><br><span class="line">accuracy = evaluate(model, test_loader)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练后准确率: <span class="subst">&#123;accuracy*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%&quot;</span>)  <span class="comment"># ≈98%!</span></span><br></pre></td></tr></table></figure></li>
</ul>
</li>
</ol>
<h4 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h4><p>为什么预训练模型有效？</p>
<ul>
<li><p>ImageNet 训练的 ResNet 已学会通用视觉特征</p>
</li>
<li><p>这些特征可以迁移到新领域（如手写字符）</p>
</li>
<li><p>即使不训练，也能达到86%准确率</p>
</li>
</ul>
<p>元学习如何提升性能？</p>
<ul>
<li><p>任务多样性：在40,000个不同任务上训练</p>
</li>
<li><p>学习”学习能力”：模型学会如何快速适应新类别</p>
</li>
<li><p>特征空间优化：调整网络使类内距离更小，类间距离更大</p>
</li>
</ul>
<p>为什么需要将单通道转三通道？</p>
<ul>
<li>预训练 ResNet 是在RGB图像上训练的，输入必须是3通道</li>
</ul>
<p>n_way 和 n_shot 如何选择？</p>
<ul>
<li>常用 5-way 5-shot，可根据任务难度调整。更多类别&#x3D;更难</li>
</ul>
<p>训练为什么要40000个任务？</p>
<ul>
<li>确保模型接触足够多的类别组合。实际可根据情况减少</li>
</ul>
<p>能否用在自己的数据集？</p>
<ul>
<li><p>当然！只需：</p>
<ul>
<li><p>按类组织图片文件夹</p>
</li>
<li><p>创建自定义Dataset</p>
</li>
<li><p>使用相同任务采样器</p>
</li>
</ul>
</li>
</ul>
<hr>
<h3 id="完整代码实例"><a href="#完整代码实例" class="headerlink" title="完整代码实例"></a>完整代码实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># %% [安装必要的库]</span></span><br><span class="line">!pip install easyfsl torchvision matplotlib &gt; /dev/null</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 库安装完成!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [导入所需库]</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> transforms</span><br><span class="line"><span class="keyword">from</span> torchvision.datasets <span class="keyword">import</span> Omniglot</span><br><span class="line"><span class="keyword">from</span> torchvision.models <span class="keyword">import</span> resnet18</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> easyfsl.samplers <span class="keyword">import</span> TaskSampler</span><br><span class="line"><span class="keyword">from</span> easyfsl.utils <span class="keyword">import</span> sliding_average</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 库导入完成!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [设置随机种子确保可重复性]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seed</span>(<span class="params">seed=<span class="number">42</span></span>):</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    torch.cuda.manual_seed_all(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">set_seed()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 随机种子设置完成!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [检查GPU可用性]</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;🚀 使用的设备: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [下载并预处理Omniglot数据集]</span></span><br><span class="line">image_size = <span class="number">28</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;⏳ 正在下载数据集...&quot;</span>)</span><br><span class="line">train_set = Omniglot(</span><br><span class="line">    root=<span class="string">&quot;./data&quot;</span>,</span><br><span class="line">    background=<span class="literal">True</span>,  <span class="comment"># 训练集</span></span><br><span class="line">    transform=transforms.Compose([</span><br><span class="line">        transforms.Grayscale(num_output_channels=<span class="number">3</span>),</span><br><span class="line">        transforms.RandomResizedCrop(image_size),</span><br><span class="line">        transforms.RandomHorizontalFlip(),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ]),</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_set = Omniglot(</span><br><span class="line">    root=<span class="string">&quot;./data&quot;</span>,</span><br><span class="line">    background=<span class="literal">False</span>,  <span class="comment"># 测试集</span></span><br><span class="line">    transform=transforms.Compose([</span><br><span class="line">        transforms.Grayscale(num_output_channels=<span class="number">3</span>),</span><br><span class="line">        transforms.Resize([<span class="built_in">int</span>(image_size * <span class="number">1.15</span>), <span class="built_in">int</span>(image_size * <span class="number">1.15</span>)]),</span><br><span class="line">        transforms.CenterCrop(image_size),</span><br><span class="line">        transforms.ToTensor(),</span><br><span class="line">    ]),</span><br><span class="line">    download=<span class="literal">True</span>,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 数据集下载和预处理完成!&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练集大小: <span class="subst">&#123;<span class="built_in">len</span>(train_set)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集大小: <span class="subst">&#123;<span class="built_in">len</span>(test_set)&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [可视化数据集样本]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_images</span>(<span class="params">images, title, images_per_row=<span class="number">5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    绘制图像网格</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    n_images = <span class="built_in">len</span>(images)</span><br><span class="line">    n_rows = (n_images + images_per_row - <span class="number">1</span>) // images_per_row</span><br><span class="line">    </span><br><span class="line">    plt.figure(figsize=(<span class="number">15</span>, <span class="number">3</span> * n_rows))</span><br><span class="line">    plt.suptitle(title, fontsize=<span class="number">16</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n_images):</span><br><span class="line">        plt.subplot(n_rows, images_per_row, i + <span class="number">1</span>)</span><br><span class="line">        <span class="comment"># 转换张量到NumPy并调整维度顺序 (C, H, W) -&gt; (H, W, C)</span></span><br><span class="line">        img = images[i].permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>).numpy()</span><br><span class="line">        <span class="comment"># 如果是灰度图（3通道相同），取第一个通道</span></span><br><span class="line">        <span class="keyword">if</span> img.shape[<span class="number">2</span>] == <span class="number">3</span> <span class="keyword">and</span> np.allclose(img[:, :, <span class="number">0</span>], img[:, :, <span class="number">1</span>]) <span class="keyword">and</span> np.allclose(img[:, :, <span class="number">0</span>], img[:, :, <span class="number">2</span>]):</span><br><span class="line">            img = img[:, :, <span class="number">0</span>]</span><br><span class="line">            plt.imshow(img, cmap=<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            plt.imshow(img)</span><br><span class="line">        plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取示例图像</span></span><br><span class="line">sample_indices = [<span class="number">0</span>, <span class="number">100</span>, <span class="number">500</span>, <span class="number">1000</span>, <span class="number">1500</span>]</span><br><span class="line">sample_images = [train_set[i][<span class="number">0</span>] <span class="keyword">for</span> i <span class="keyword">in</span> sample_indices]</span><br><span class="line">plot_images(sample_images, <span class="string">&quot;Omniglot 数据集示例&quot;</span>, images_per_row=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [定义原型网络模型]</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">PrototypicalNetworks</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, backbone: nn.Module</span>):</span><br><span class="line">        <span class="built_in">super</span>(PrototypicalNetworks, <span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.backbone = backbone</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params"></span></span><br><span class="line"><span class="params">        self,</span></span><br><span class="line"><span class="params">        support_images: torch.Tensor,</span></span><br><span class="line"><span class="params">        support_labels: torch.Tensor,</span></span><br><span class="line"><span class="params">        query_images: torch.Tensor,</span></span><br><span class="line"><span class="params">    </span>) -&gt; torch.Tensor:</span><br><span class="line">        <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">        使用支持集预测查询图像的标签</span></span><br><span class="line"><span class="string">        &quot;&quot;&quot;</span></span><br><span class="line">        <span class="comment"># 提取特征</span></span><br><span class="line">        z_support = <span class="variable language_">self</span>.backbone(support_images)</span><br><span class="line">        z_query = <span class="variable language_">self</span>.backbone(query_images)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取类别数</span></span><br><span class="line">        unique_labels = torch.unique(support_labels)</span><br><span class="line">        n_way = <span class="built_in">len</span>(unique_labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算每个类的原型（均值向量）</span></span><br><span class="line">        z_proto = torch.cat([</span><br><span class="line">            z_support[support_labels == label].mean(<span class="number">0</span>, keepdim=<span class="literal">True</span>)</span><br><span class="line">            <span class="keyword">for</span> label <span class="keyword">in</span> unique_labels</span><br><span class="line">        ])</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算欧氏距离并转为相似度分数</span></span><br><span class="line">        dists = torch.cdist(z_query, z_proto)</span><br><span class="line">        scores = -dists</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> scores</span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化模型</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🛠️ 正在初始化模型...&quot;</span>)</span><br><span class="line">convolutional_network = resnet18(pretrained=<span class="literal">True</span>)</span><br><span class="line">convolutional_network.fc = nn.Flatten()  <span class="comment"># 替换全连接层为展平层</span></span><br><span class="line">model = PrototypicalNetworks(convolutional_network).to(device)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 模型初始化完成!&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型结构:\n<span class="subst">&#123;model&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [配置任务参数]</span></span><br><span class="line">N_WAY = <span class="number">5</span>   <span class="comment"># 每个任务的类别数</span></span><br><span class="line">N_SHOT = <span class="number">5</span>  <span class="comment"># 每个类的支持样本数</span></span><br><span class="line">N_QUERY = <span class="number">10</span>  <span class="comment"># 每个类的查询样本数</span></span><br><span class="line">N_EVALUATION_TASKS = <span class="number">100</span>  <span class="comment"># 评估任务数</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;🔧 任务配置: <span class="subst">&#123;N_WAY&#125;</span>-way, <span class="subst">&#123;N_SHOT&#125;</span>-shot, <span class="subst">&#123;N_QUERY&#125;</span>查询样本&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [创建测试任务加载器]</span></span><br><span class="line">test_set.get_labels = <span class="keyword">lambda</span>: [instance[<span class="number">1</span>] <span class="keyword">for</span> instance <span class="keyword">in</span> test_set._flat_character_images]</span><br><span class="line">test_sampler = TaskSampler(</span><br><span class="line">    test_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_EVALUATION_TASKS</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_set,</span><br><span class="line">    batch_sampler=test_sampler,</span><br><span class="line">    num_workers=<span class="number">2</span>,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=test_sampler.episodic_collate_fn,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 测试任务加载器创建完成!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [可视化任务样本]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;📊 可视化一个少样本任务...&quot;</span>)</span><br><span class="line">(support_images, support_labels, </span><br><span class="line"> query_images, query_labels, class_ids) = <span class="built_in">next</span>(<span class="built_in">iter</span>(test_loader))</span><br><span class="line"></span><br><span class="line">plot_images(support_images, <span class="string">f&quot;支持集图像 (<span class="subst">&#123;N_WAY&#125;</span>类, 每类<span class="subst">&#123;N_SHOT&#125;</span>样本)&quot;</span>, images_per_row=N_SHOT)</span><br><span class="line">plot_images(query_images, <span class="string">f&quot;查询集图像 (<span class="subst">&#123;N_WAY&#125;</span>类, 每类<span class="subst">&#123;N_QUERY&#125;</span>样本)&quot;</span>, images_per_row=N_QUERY)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [在预训练模型上评估单个任务]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🧪 使用预训练模型进行测试...&quot;</span>)</span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line"><span class="keyword">with</span> torch.no_grad():</span><br><span class="line">    <span class="comment"># 获取模型预测</span></span><br><span class="line">    scores = model(</span><br><span class="line">        support_images.to(device),</span><br><span class="line">        support_labels.to(device),</span><br><span class="line">        query_images.to(device)</span><br><span class="line">    )</span><br><span class="line">    _, predicted_labels = torch.<span class="built_in">max</span>(scores, <span class="number">1</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 打印结果</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;\n真实标签 vs 预测标签:&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">min</span>(<span class="number">10</span>, <span class="built_in">len</span>(query_labels))):  <span class="comment"># 只显示前10个结果</span></span><br><span class="line">        true_char = test_set._characters[class_ids[query_labels[i]]]</span><br><span class="line">        pred_char = test_set._characters[class_ids[predicted_labels[i]]]</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;true_char&#125;</span> → <span class="subst">&#123;pred_char&#125;</span> <span class="subst">&#123;<span class="string">&#x27;✅&#x27;</span> <span class="keyword">if</span> true_char == pred_char <span class="keyword">else</span> <span class="string">&#x27;❌&#x27;</span>&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [评估函数]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">evaluate</span>(<span class="params">data_loader: DataLoader, model: nn.Module, device: torch.device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    在给定数据加载器上评估模型</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    total_predictions = <span class="number">0</span></span><br><span class="line">    correct_predictions = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> tqdm(data_loader, desc=<span class="string">&quot;评估中&quot;</span>, leave=<span class="literal">False</span>):</span><br><span class="line">            support_images, support_labels, query_images, query_labels, _ = batch</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 获取预测分数</span></span><br><span class="line">            scores = model(</span><br><span class="line">                support_images.to(device),</span><br><span class="line">                support_labels.to(device),</span><br><span class="line">                query_images.to(device)</span><br><span class="line">            )</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算准确率</span></span><br><span class="line">            _, predictions = torch.<span class="built_in">max</span>(scores.data, <span class="number">1</span>)</span><br><span class="line">            correct_predictions += (predictions == query_labels.to(device)).<span class="built_in">sum</span>().item()</span><br><span class="line">            total_predictions += <span class="built_in">len</span>(query_labels)</span><br><span class="line">    </span><br><span class="line">    accuracy = <span class="number">100</span> * correct_predictions / total_predictions</span><br><span class="line">    <span class="keyword">return</span> accuracy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估预训练模型</span></span><br><span class="line">pretrained_acc = evaluate(test_loader, model, device)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;🎯 预训练模型准确率: <span class="subst">&#123;pretrained_acc:<span class="number">.2</span>f&#125;</span>% (基于<span class="subst">&#123;N_EVALUATION_TASKS&#125;</span>个任务)&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [准备训练]</span></span><br><span class="line"><span class="comment"># 配置训练参数</span></span><br><span class="line">N_TRAINING_EPISODES = <span class="number">1000</span>  <span class="comment"># 减少训练任务数以加快演示速度</span></span><br><span class="line">LR = <span class="number">0.001</span></span><br><span class="line">EPOCHS = <span class="number">1</span>  <span class="comment"># 单个epoch用于演示</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🚂 准备训练...&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练配置: <span class="subst">&#123;N_TRAINING_EPISODES&#125;</span>个任务, LR=<span class="subst">&#123;LR&#125;</span>, Epochs=<span class="subst">&#123;EPOCHS&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建训练数据加载器</span></span><br><span class="line">train_set.get_labels = <span class="keyword">lambda</span>: [instance[<span class="number">1</span>] <span class="keyword">for</span> instance <span class="keyword">in</span> train_set._flat_character_images]</span><br><span class="line">train_sampler = TaskSampler(</span><br><span class="line">    train_set, n_way=N_WAY, n_shot=N_SHOT, n_query=N_QUERY, n_tasks=N_TRAINING_EPISODES</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_set,</span><br><span class="line">    batch_sampler=train_sampler,</span><br><span class="line">    num_workers=<span class="number">2</span>,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=train_sampler.episodic_collate_fn,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=LR)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [训练循环]</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">fit</span>(<span class="params">model, support_images, support_labels, query_images, query_labels, optimizer, criterion</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    在单个任务上训练模型</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 前向传播</span></span><br><span class="line">    scores = model(</span><br><span class="line">        support_images.to(device),</span><br><span class="line">        support_labels.to(device),</span><br><span class="line">        query_images.to(device)</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算损失</span></span><br><span class="line">    loss = criterion(scores, query_labels.to(device))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 反向传播</span></span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> loss.item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🔥 开始训练...&quot;</span>)</span><br><span class="line">model.train()</span><br><span class="line">train_losses = []</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(EPOCHS):</span><br><span class="line">    epoch_losses = []</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">with</span> tqdm(<span class="built_in">enumerate</span>(train_loader), total=<span class="built_in">len</span>(train_loader), desc=<span class="string">f&quot;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;EPOCHS&#125;</span>&quot;</span>) <span class="keyword">as</span> pbar:</span><br><span class="line">        <span class="keyword">for</span> i, batch <span class="keyword">in</span> pbar:</span><br><span class="line">            support_images, support_labels, query_images, query_labels, _ = batch</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 训练步骤</span></span><br><span class="line">            loss = fit(model, support_images, support_labels, query_images, query_labels, optimizer, criterion)</span><br><span class="line">            epoch_losses.append(loss)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 更新进度条</span></span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                pbar.set_postfix(loss=sliding_average(epoch_losses, window_size=<span class="number">10</span>))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算平均epoch损失</span></span><br><span class="line">    avg_loss = <span class="built_in">sum</span>(epoch_losses) / <span class="built_in">len</span>(epoch_losses)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span> 完成! 平均损失: <span class="subst">&#123;avg_loss:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    train_losses.extend(epoch_losses)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 绘制训练损失</span></span><br><span class="line">plt.figure(figsize=(<span class="number">10</span>, <span class="number">5</span>))</span><br><span class="line">plt.plot(train_losses, label=<span class="string">&#x27;训练损失&#x27;</span>)</span><br><span class="line">plt.plot([sliding_average(train_losses, i+<span class="number">1</span>) <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(train_losses))], </span><br><span class="line">         label=<span class="string">&#x27;滑动平均&#x27;</span>, alpha=<span class="number">0.7</span>)</span><br><span class="line">plt.xlabel(<span class="string">&#x27;迭代次数&#x27;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&#x27;损失&#x27;</span>)</span><br><span class="line">plt.title(<span class="string">&#x27;训练损失曲线&#x27;</span>)</span><br><span class="line">plt.legend()</span><br><span class="line">plt.grid(<span class="literal">True</span>)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;✅ 训练完成!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [评估训练后的模型]</span></span><br><span class="line">trained_acc = evaluate(test_loader, model, device)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;🎯 训练后模型准确率: <span class="subst">&#123;trained_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;📈 准确率提升: <span class="subst">&#123;trained_acc - pretrained_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [保存模型]</span></span><br><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;prototypical_networks.pth&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;💾 模型已保存为 &#x27;prototypical_networks.pth&#x27;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># %% [总结报告]</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span> + <span class="string">&quot;=&quot;</span>*<span class="number">50</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;🏁 实验总结&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">50</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;预训练模型准确率: <span class="subst">&#123;pretrained_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练后模型准确率: <span class="subst">&#123;trained_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;准确率提升: <span class="subst">&#123;trained_acc - pretrained_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练任务数: <span class="subst">&#123;N_TRAINING_EPISODES&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试任务数: <span class="subst">&#123;N_EVALUATION_TASKS&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;=&quot;</span>*<span class="number">50</span>)</span><br></pre></td></tr></table></figure>

<hr>
<hr>
<h2 id="Train-a-model-with-Episodic-Training"><a href="#Train-a-model-with-Episodic-Training" class="headerlink" title="Train a model with Episodic Training"></a>Train a model with Episodic Training</h2><h3 id="入门："><a href="#入门：" class="headerlink" title="入门："></a>入门：</h3><p><strong>1. 导入</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> google.colab</span><br><span class="line">    colab = <span class="literal">True</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    colab = <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> colab <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># 在 Google Colab 中运行</span></span><br><span class="line">    <span class="comment"># 克隆仓库</span></span><br><span class="line">    !git clone https://github.com/sicara/easy-few-shot-learning</span><br><span class="line">    %cd easy-few-shot-learning</span><br><span class="line">    !pip install .</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 在本地运行</span></span><br><span class="line">    <span class="comment"># 确保工作目录是项目的根目录</span></span><br><span class="line">    <span class="comment"># 确保已安装 easyfsl！</span></span><br><span class="line">    %cd ..</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure>

<p><strong>2. 通过设置随机种子来确保结果的可复现性。</strong></p>
<p>我们将为我们可能使用的所有随机包设置种子，再加上一些其他设置以使 CUDA 具有确定性（参见<a target="_blank" rel="noopener" href="https://docs.pytorch.org/docs/stable/notes/randomness.html">这里</a>）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">random_seed = <span class="number">0</span></span><br><span class="line">np.random.seed(random_seed)</span><br><span class="line">torch.manual_seed(random_seed)</span><br><span class="line">random.seed(random_seed)</span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<p><strong>3. 接下来，定义问题的形式（shape）。</strong></p>
<p>定义设置，如使用的设备（如果你没有 CUDA 请更改它）或用于数据加载的工作进程（workers）数量。。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">n_way = <span class="number">5</span></span><br><span class="line">n_shot = <span class="number">5</span></span><br><span class="line">n_query = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span></span><br><span class="line">n_workers = <span class="number">12</span></span><br></pre></td></tr></table></figure>

<h3 id="训练："><a href="#训练：" class="headerlink" title="训练："></a>训练：</h3><p><strong>1. 首先，我们为训练和验证定义数据加载器（data loaders）。</strong></p>
<p>可以看到我选择在这个笔记本中使用 CUB 数据集，因为它是一个小型数据集，因此我们可以较快地获得良好的结果。</p>
<p>我们使用 EasyFSL 内置的对象 <code>CUB</code> 和 <code>TaskSampler</code>。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载 CUB 数据集</span></span><br><span class="line">!make download-cub</span><br><span class="line"><span class="keyword">from</span> easyfsl.datasets <span class="keyword">import</span> CUB</span><br><span class="line"><span class="keyword">from</span> easyfsl.samplers <span class="keyword">import</span> TaskSampler</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">n_tasks_per_epoch = <span class="number">500</span></span><br><span class="line">n_validation_tasks = <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化数据集</span></span><br><span class="line">train_set = CUB(split=<span class="string">&quot;train&quot;</span>, training=<span class="literal">True</span>)</span><br><span class="line">val_set = CUB(split=<span class="string">&quot;val&quot;</span>, training=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 这些是特殊的批采样器（batch samplers），它们按照预定义的形状（shape）采样小样本分类任务</span></span><br><span class="line">train_sampler = TaskSampler(</span><br><span class="line">    train_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch</span><br><span class="line">)</span><br><span class="line">val_sampler = TaskSampler(</span><br><span class="line">    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 最后，数据加载器（DataLoader）。我们自定义 collate_fn，以便批次数据会被组织成以下形状：</span></span><br><span class="line"><span class="comment"># (support_images, support_labels, query_images, query_labels, class_ids)</span></span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_set,</span><br><span class="line">    batch_sampler=train_sampler,</span><br><span class="line">    num_workers=n_workers,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=train_sampler.episodic_collate_fn,</span><br><span class="line">)</span><br><span class="line">val_loader = DataLoader(</span><br><span class="line">    val_set,</span><br><span class="line">    batch_sampler=val_sampler,</span><br><span class="line">    num_workers=n_workers,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=val_sampler.episodic_collate_fn,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>2. 定义网络</strong></p>
<p>这里我选择了原型网络（Prototypical Networks）和 PyTorch 内置的 ResNet18，因为它很简单。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> easyfsl.methods <span class="keyword">import</span> PrototypicalNetworks, FewShotClassifier</span><br><span class="line"><span class="keyword">from</span> easyfsl.modules <span class="keyword">import</span> resnet12</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">convolutional_network = resnet12()</span><br><span class="line">few_shot_classifier = PrototypicalNetworks(convolutional_network).to(DEVICE)</span><br></pre></td></tr></table></figure>

<p><strong>3. 定义训练辅助工具</strong></p>
<p>我选择使用随机梯度下降（Stochastic Gradient Descent）进行 200 个周期（epochs），并使用一个调度器（scheduler）在第 120 和 160 个周期后将学习率除以 10。该策略源自这个<a target="_blank" rel="noopener" href="https://github.com/fiveai/on-episodes-fsl">仓库</a>。</p>
<p>附：使用TensorBoard观察训练曲线。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD, Optimizer</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> MultiStepLR</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">LOSS_FUNCTION = nn.CrossEntropyLoss()</span><br><span class="line"></span><br><span class="line">n_epochs = <span class="number">200</span></span><br><span class="line">scheduler_milestones = [<span class="number">120</span>, <span class="number">160</span>]</span><br><span class="line">scheduler_gamma = <span class="number">0.1</span></span><br><span class="line">learning_rate = <span class="number">1e-2</span></span><br><span class="line">tb_logs_dir = Path(<span class="string">&quot;.&quot;</span>)</span><br><span class="line"></span><br><span class="line">train_optimizer = SGD(</span><br><span class="line">    few_shot_classifier.parameters(), lr=learning_rate, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">5e-4</span></span><br><span class="line">)</span><br><span class="line">train_scheduler = MultiStepLR(</span><br><span class="line">    train_optimizer,</span><br><span class="line">    milestones=scheduler_milestones,</span><br><span class="line">    gamma=scheduler_gamma,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tb_writer = SummaryWriter(log_dir=<span class="built_in">str</span>(tb_logs_dir))</span><br></pre></td></tr></table></figure>

<p>这里我们定义执行一个训练周期的函数。</p>
<p>我们使用 <code>tqdm</code> 在日志中实时监控训练进度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">training_epoch</span>(<span class="params"></span></span><br><span class="line"><span class="params">    model: FewShotClassifier, data_loader: DataLoader, optimizer: Optimizer</span></span><br><span class="line"><span class="params"></span>):</span><br><span class="line">    all_loss = []</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">with</span> tqdm(</span><br><span class="line">        <span class="built_in">enumerate</span>(data_loader), total=<span class="built_in">len</span>(data_loader), desc=<span class="string">&quot;Training&quot;</span></span><br><span class="line">    ) <span class="keyword">as</span> tqdm_train:</span><br><span class="line">        <span class="keyword">for</span> episode_index, (</span><br><span class="line">            support_images,</span><br><span class="line">            support_labels,</span><br><span class="line">            query_images,</span><br><span class="line">            query_labels,</span><br><span class="line">            _,</span><br><span class="line">        ) <span class="keyword">in</span> tqdm_train:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            model.process_support_set(</span><br><span class="line">                support_images.to(DEVICE), support_labels.to(DEVICE)</span><br><span class="line">            )</span><br><span class="line">            classification_scores = model(query_images.to(DEVICE))</span><br><span class="line"></span><br><span class="line">            loss = LOSS_FUNCTION(classification_scores, query_labels.to(DEVICE))</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line"></span><br><span class="line">            all_loss.append(loss.item())</span><br><span class="line"></span><br><span class="line">            tqdm_train.set_postfix(loss=mean(all_loss))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mean(all_loss)</span><br></pre></td></tr></table></figure>

<p>为了执行验证，我们将使用来自 <code>easyfsl.methods.utils</code> 的内置 <code>evaluate</code> 函数。</p>
<p><strong>4. 添加功能记录在验证集上表现最佳模型的状态。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> easyfsl.utils <span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">best_state = few_shot_classifier.state_dict()</span><br><span class="line">best_validation_accuracy = <span class="number">0.0</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>&quot;</span>)</span><br><span class="line">    average_loss = training_epoch(few_shot_classifier, train_loader, train_optimizer)</span><br><span class="line">    validation_accuracy = evaluate(</span><br><span class="line">        few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=<span class="string">&quot;Validation&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> validation_accuracy &gt; best_validation_accuracy:</span><br><span class="line">        best_validation_accuracy = validation_accuracy</span><br><span class="line">        best_state = copy.deepcopy(few_shot_classifier.state_dict())</span><br><span class="line">        <span class="comment"># state_dict() 返回对仍在演变的模型状态的引用，因此我们进行深拷贝</span></span><br><span class="line">        <span class="comment"># https://pytorch.org/tutorials/beginner/saving_loading_models</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;叮叮叮！我们找到了一个新的最佳模型！&quot;</span>)</span><br><span class="line"></span><br><span class="line">    tb_writer.add_scalar(<span class="string">&quot;Train/loss&quot;</span>, average_loss, epoch)</span><br><span class="line">    tb_writer.add_scalar(<span class="string">&quot;Val/acc&quot;</span>, validation_accuracy, epoch)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通知调度器我们完成了一个周期</span></span><br><span class="line">    <span class="comment"># 这样它就知道何时降低学习率</span></span><br><span class="line">    train_scheduler.step()</span><br></pre></td></tr></table></figure>

<p>现在，如果你愿意，可以取回最佳模型的状态。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">few_shot_classifier.load_state_dict(best_state)</span><br></pre></td></tr></table></figure>

<h3 id="评估："><a href="#评估：" class="headerlink" title="评估："></a>评估：</h3><p><strong>1. 获取测试数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">n_test_tasks = <span class="number">1000</span></span><br><span class="line"></span><br><span class="line">test_set = CUB(split=<span class="string">&quot;test&quot;</span>, training=<span class="literal">False</span>)</span><br><span class="line">test_sampler = TaskSampler(</span><br><span class="line">    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks</span><br><span class="line">)</span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_set,</span><br><span class="line">    batch_sampler=test_sampler,</span><br><span class="line">    num_workers=n_workers,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=test_sampler.episodic_collate_fn,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>2. 在测试数据上运行小样本分类器。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">accuracy = evaluate(few_shot_classifier, test_loader, device=DEVICE)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;平均准确率: <span class="subst">&#123;(<span class="number">100</span> * accuracy):<span class="number">.2</span>f&#125;</span> %&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="完整代码实例-1"><a href="#完整代码实例-1" class="headerlink" title="完整代码实例"></a>完整代码实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">基于情景训练（Episodic Training）的小样本学习项目</span></span><br><span class="line"><span class="string">使用EasyFSL库和CUB数据集训练原型网络（Prototypical Networks）</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入必要的库</span></span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否在Google Colab环境中运行</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> google.colab</span><br><span class="line">    colab = <span class="literal">True</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    colab = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> colab:</span><br><span class="line">    <span class="comment"># 在Google Colab中运行</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;在Google Colab环境中运行&quot;</span>)</span><br><span class="line">    <span class="comment"># 克隆仓库并安装EasyFSL</span></span><br><span class="line">    !git clone https://github.com/sicara/easy-few-shot-learning</span><br><span class="line">    %cd easy-few-shot-learning</span><br><span class="line">    !pip install .</span><br><span class="line">    <span class="comment"># 下载CUB数据集</span></span><br><span class="line">    !make download-cub</span><br><span class="line">    %cd ..</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 本地运行 - 确保easyfsl已安装</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;在本地环境中运行&quot;</span>)</span><br><span class="line">    <span class="comment"># 注意：本地运行时需要手动下载CUB数据集</span></span><br><span class="line">    <span class="comment"># 数据集可从http://www.vision.caltech.edu/visipedia/CUB-200-2011.html下载</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 从EasyFSL导入必要组件</span></span><br><span class="line"><span class="keyword">from</span> easyfsl.datasets <span class="keyword">import</span> CUB</span><br><span class="line"><span class="keyword">from</span> easyfsl.samplers <span class="keyword">import</span> TaskSampler</span><br><span class="line"><span class="keyword">from</span> easyfsl.methods <span class="keyword">import</span> PrototypicalNetworks</span><br><span class="line"><span class="keyword">from</span> easyfsl.utils <span class="keyword">import</span> evaluate</span><br><span class="line"><span class="keyword">from</span> easyfsl.modules <span class="keyword">import</span> resnet12</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">set_seed</span>(<span class="params">seed=<span class="number">0</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    设置随机种子以确保结果可复现</span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        seed (int): 随机种子值</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    random.seed(seed)</span><br><span class="line">    np.random.seed(seed)</span><br><span class="line">    torch.manual_seed(seed)</span><br><span class="line">    <span class="keyword">if</span> torch.cuda.is_available():</span><br><span class="line">        torch.cuda.manual_seed_all(seed)</span><br><span class="line">    torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">    torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_data_loaders</span>(<span class="params">n_way, n_shot, n_query, n_tasks_per_epoch, n_validation_tasks</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    创建训练、验证和测试数据加载器</span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        n_way: 每个任务中的类别数</span></span><br><span class="line"><span class="string">        n_shot: 每个类别的支持样本数</span></span><br><span class="line"><span class="string">        n_query: 每个类别的查询样本数</span></span><br><span class="line"><span class="string">        n_tasks_per_epoch: 每个训练周期的任务数</span></span><br><span class="line"><span class="string">        n_validation_tasks: 验证任务数</span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        train_loader, val_loader, test_loader: 数据加载器</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 创建数据集</span></span><br><span class="line">    train_set = CUB(split=<span class="string">&quot;train&quot;</span>, training=<span class="literal">True</span>)</span><br><span class="line">    val_set = CUB(split=<span class="string">&quot;val&quot;</span>, training=<span class="literal">False</span>)</span><br><span class="line">    test_set = CUB(split=<span class="string">&quot;test&quot;</span>, training=<span class="literal">False</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建任务采样器</span></span><br><span class="line">    train_sampler = TaskSampler(</span><br><span class="line">        train_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_tasks_per_epoch</span><br><span class="line">    )</span><br><span class="line">    val_sampler = TaskSampler(</span><br><span class="line">        val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 创建数据加载器</span></span><br><span class="line">    train_loader = DataLoader(</span><br><span class="line">        train_set,</span><br><span class="line">        batch_sampler=train_sampler,</span><br><span class="line">        num_workers=<span class="number">4</span>,</span><br><span class="line">        pin_memory=<span class="literal">True</span>,</span><br><span class="line">        collate_fn=train_sampler.episodic_collate_fn,</span><br><span class="line">    )</span><br><span class="line">    val_loader = DataLoader(</span><br><span class="line">        val_set,</span><br><span class="line">        batch_sampler=val_sampler,</span><br><span class="line">        num_workers=<span class="number">4</span>,</span><br><span class="line">        pin_memory=<span class="literal">True</span>,</span><br><span class="line">        collate_fn=val_sampler.episodic_collate_fn,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> train_loader, val_loader, test_set</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">training_epoch</span>(<span class="params">model, data_loader, optimizer, loss_function, device</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    执行一个训练周期</span></span><br><span class="line"><span class="string">    参数:</span></span><br><span class="line"><span class="string">        model: 要训练的模型</span></span><br><span class="line"><span class="string">        data_loader: 训练数据加载器</span></span><br><span class="line"><span class="string">        optimizer: 优化器</span></span><br><span class="line"><span class="string">        loss_function: 损失函数</span></span><br><span class="line"><span class="string">        device: 计算设备 (CPU/GPU)</span></span><br><span class="line"><span class="string">    返回:</span></span><br><span class="line"><span class="string">        average_loss: 该周期的平均损失</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    all_losses = []</span><br><span class="line">    model.train()  <span class="comment"># 设置模型为训练模式</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用tqdm显示训练进度</span></span><br><span class="line">    progress_bar = tqdm(<span class="built_in">enumerate</span>(data_loader), total=<span class="built_in">len</span>(data_loader), desc=<span class="string">&quot;训练&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> episode_index, (support_images, support_labels, query_images, query_labels, _) <span class="keyword">in</span> progress_bar:</span><br><span class="line">        <span class="comment"># 将数据移动到指定设备</span></span><br><span class="line">        support_images = support_images.to(device)</span><br><span class="line">        support_labels = support_labels.to(device)</span><br><span class="line">        query_images = query_images.to(device)</span><br><span class="line">        query_labels = query_labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 梯度清零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 处理支持集（计算原型）</span></span><br><span class="line">        model.process_support_set(support_images, support_labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算查询集的分类分数</span></span><br><span class="line">        classification_scores = model(query_images)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 计算损失</span></span><br><span class="line">        loss = loss_function(classification_scores, query_labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向传播</span></span><br><span class="line">        loss.backward()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新权重</span></span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录损失</span></span><br><span class="line">        all_losses.append(loss.item())</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新进度条显示</span></span><br><span class="line">        progress_bar.set_postfix(loss=mean(all_losses))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> mean(all_losses)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    <span class="string">&quot;&quot;&quot;主函数：训练和评估模型&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 1. 设置参数</span></span><br><span class="line">    n_way = <span class="number">5</span>          <span class="comment"># 每个任务中的类别数</span></span><br><span class="line">    n_shot = <span class="number">5</span>         <span class="comment"># 每个类别的支持样本数</span></span><br><span class="line">    n_query = <span class="number">10</span>       <span class="comment"># 每个类别的查询样本数</span></span><br><span class="line">    n_epochs = <span class="number">50</span>      <span class="comment"># 训练周期数（实际研究中通常为100-200）</span></span><br><span class="line">    n_tasks_per_epoch = <span class="number">100</span>       <span class="comment"># 每个训练周期的任务数</span></span><br><span class="line">    n_validation_tasks = <span class="number">100</span>      <span class="comment"># 验证任务数</span></span><br><span class="line">    n_test_tasks = <span class="number">200</span>            <span class="comment"># 测试任务数</span></span><br><span class="line">    learning_rate = <span class="number">0.001</span>         <span class="comment"># 学习率</span></span><br><span class="line">    milestones = [<span class="number">30</span>, <span class="number">40</span>]         <span class="comment"># 学习率调整的周期点</span></span><br><span class="line">    gamma = <span class="number">0.1</span>                   <span class="comment"># 学习率调整因子</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 2. 设置随机种子</span></span><br><span class="line">    set_seed(<span class="number">0</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3. 设置计算设备</span></span><br><span class="line">    device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;使用设备: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 4. 创建数据加载器</span></span><br><span class="line">    train_loader, val_loader, test_set = create_data_loaders(</span><br><span class="line">        n_way, n_shot, n_query, n_tasks_per_epoch, n_validation_tasks</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 5. 创建模型</span></span><br><span class="line">    <span class="comment"># 使用ResNet12作为特征提取器</span></span><br><span class="line">    backbone = resnet12()</span><br><span class="line">    model = PrototypicalNetworks(backbone).to(device)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 6. 设置优化器和学习率调度器</span></span><br><span class="line">    optimizer = optim.Adam(model.parameters(), lr=learning_rate)</span><br><span class="line">    scheduler = optim.lr_scheduler.MultiStepLR(</span><br><span class="line">        optimizer, milestones=milestones, gamma=gamma</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 7. 设置损失函数</span></span><br><span class="line">    loss_function = nn.CrossEntropyLoss()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 8. 设置TensorBoard记录</span></span><br><span class="line">    log_dir = Path(<span class="string">&quot;./logs&quot;</span>)</span><br><span class="line">    log_dir.mkdir(exist_ok=<span class="literal">True</span>)</span><br><span class="line">    writer = SummaryWriter(log_dir=<span class="built_in">str</span>(log_dir))</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 9. 训练模型</span></span><br><span class="line">    best_accuracy = <span class="number">0.0</span></span><br><span class="line">    best_model_state = <span class="literal">None</span></span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;开始训练...&quot;</span>)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n周期 [<span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;n_epochs&#125;</span>]&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 训练一个周期</span></span><br><span class="line">        train_loss = training_epoch(model, train_loader, optimizer, loss_function, device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 在验证集上评估</span></span><br><span class="line">        val_accuracy = evaluate(model, val_loader, device=device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录到TensorBoard</span></span><br><span class="line">        writer.add_scalar(<span class="string">&quot;Loss/Train&quot;</span>, train_loss, epoch)</span><br><span class="line">        writer.add_scalar(<span class="string">&quot;Accuracy/Validation&quot;</span>, val_accuracy, epoch)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 保存最佳模型</span></span><br><span class="line">        <span class="keyword">if</span> val_accuracy &gt; best_accuracy:</span><br><span class="line">            best_accuracy = val_accuracy</span><br><span class="line">            best_model_state = copy.deepcopy(model.state_dict())</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;🎉 发现新最佳模型! 验证准确率: <span class="subst">&#123;val_accuracy:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新学习率</span></span><br><span class="line">        scheduler.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 10. 加载最佳模型</span></span><br><span class="line">    model.load_state_dict(best_model_state)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;最佳验证准确率: <span class="subst">&#123;best_accuracy:<span class="number">.4</span>f&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 11. 在测试集上评估</span></span><br><span class="line">    <span class="comment"># 创建测试集采样器和加载器</span></span><br><span class="line">    test_sampler = TaskSampler(</span><br><span class="line">        test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks</span><br><span class="line">    )</span><br><span class="line">    test_loader = DataLoader(</span><br><span class="line">        test_set,</span><br><span class="line">        batch_sampler=test_sampler,</span><br><span class="line">        num_workers=<span class="number">4</span>,</span><br><span class="line">        pin_memory=<span class="literal">True</span>,</span><br><span class="line">        collate_fn=test_sampler.episodic_collate_fn,</span><br><span class="line">    )</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 评估模型</span></span><br><span class="line">    test_accuracy = evaluate(model, test_loader, device=device)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n测试准确率: <span class="subst">&#123;test_accuracy:<span class="number">.4</span>f&#125;</span> (<span class="subst">&#123;test_accuracy*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%)&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 12. 保存模型</span></span><br><span class="line">    torch.save(model.state_dict(), <span class="string">&quot;best_model.pth&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;模型已保存为 &#x27;best_model.pth&#x27;&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 关闭TensorBoard写入器</span></span><br><span class="line">    writer.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p><strong>项目说明</strong></p>
<ol>
<li><strong>环境设置</strong>：<ul>
<li>自动检测是否在Google Colab中运行</li>
<li>在Colab中自动克隆仓库、安装依赖并下载数据集</li>
<li>本地运行时需要预先安装easyfsl库</li>
</ul>
</li>
<li><strong>核心功能</strong>：<ul>
<li><code>set_seed()</code>：设置随机种子确保结果可复现</li>
<li><code>create_data_loaders()</code>：创建任务采样器和数据加载器</li>
<li><code>training_epoch()</code>：执行单个训练周期</li>
<li><code>main()</code>：主函数协调整个训练流程</li>
</ul>
</li>
<li><strong>训练流程</strong>：<ul>
<li>使用CUB鸟类数据集</li>
<li>采用原型网络（Prototypical Networks）</li>
<li>使用ResNet12作为特征提取器</li>
<li>每个训练周期包含多个小样本分类任务</li>
<li>在验证集上监控性能并保存最佳模型</li>
<li>最终在测试集上评估模型性能</li>
</ul>
</li>
<li><strong>参数说明</strong>：<ul>
<li><code>n_way</code>：每个任务中的类别数</li>
<li><code>n_shot</code>：每个类别的支持样本数</li>
<li><code>n_query</code>：每个类别的查询样本数</li>
<li><code>n_epochs</code>：训练周期数（实际研究中通常为100-200）</li>
<li><code>learning_rate</code>：初始学习率</li>
</ul>
</li>
<li><strong>输出</strong>：<ul>
<li>训练过程中的损失和准确率记录到TensorBoard</li>
<li>保存最佳模型到文件</li>
<li>在测试集上输出最终准确率</li>
</ul>
</li>
</ol>
<p><strong>运行说明</strong></p>
<ol>
<li><strong>在Google Colab中运行</strong>：<ul>
<li>复制上述代码到Colab笔记本</li>
<li>选择GPU运行时环境（运行时 → 更改运行时类型 → GPU）</li>
<li>直接运行即可</li>
</ul>
</li>
<li><strong>在本地运行</strong>：<ul>
<li>安装依赖：<code>pip install easyfsl torch torchvision tensorboard</code></li>
<li>手动下载CUB数据集（<a target="_blank" rel="noopener" href="http://www.vision.caltech.edu/visipedia/CUB-200-2011.html%EF%BC%89">http://www.vision.caltech.edu/visipedia/CUB-200-2011.html）</a></li>
<li>解压数据集到<code>./data/CUB_200_2011</code>目录</li>
</ul>
</li>
<li><strong>调整训练参数</strong>：<ul>
<li>增加<code>n_epochs</code>（50→200）可获得更好性能</li>
<li>增加<code>n_tasks_per_epoch</code>（100→500）可提高训练稳定性</li>
<li>调整<code>learning_rate</code>可优化收敛速度</li>
</ul>
</li>
</ol>
<p>这个项目完整实现了小样本学习中的情景训练流程，适合作为学习小样本学习和元学习的入门项目。</p>
<hr>
<h2 id="Train-a-model-with-Classical-Training"><a href="#Train-a-model-with-Classical-Training" class="headerlink" title="Train a model with Classical Training"></a>Train a model with Classical Training</h2><p>尽管情景训练在小样本学习研究的早期吸引了大量兴趣，但最近的研究表明，使用简单的跨所有训练类别的交叉熵损失（cross entropy loss）也可以达到有竞争力的结果。</p>
<p>因此，使用这种经典过程来训练主干网络（backbone）变得越来越普遍，该主干网络将在测试时用于所有比较的方法。</p>
<p>这实际上更能代表实际用例：情景训练假设在训练时，你就能访问到测试时将遇到的少样本任务的形式（你确实在情景训练中选择了一个特定的类别数）。你还在网络的训练中“强行”融入了推理方法。将小样本学习的逻辑切换到推理阶段（即不使用情景训练）可以使方法对主干网络保持不可知性（agnostic）。</p>
<p>尽管如此，如果你需要进行情景训练，我们也提供了一个示例笔记本。</p>
<h3 id="开始："><a href="#开始：" class="headerlink" title="开始："></a>开始：</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> google.colab</span><br><span class="line">    colab = <span class="literal">True</span></span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    colab = <span class="literal">False</span></span><br><span class="line"><span class="keyword">if</span> colab <span class="keyword">is</span> <span class="literal">True</span>:</span><br><span class="line">    <span class="comment"># 在 Google Colab 中运行</span></span><br><span class="line">    <span class="comment"># 克隆仓库</span></span><br><span class="line">    !git clone https://github.com/sicara/easy-few-shot-learning</span><br><span class="line">    %cd easy-few-shot-learning</span><br><span class="line">    !pip install .</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 在本地运行</span></span><br><span class="line">    <span class="comment"># 确保工作目录是项目的根目录</span></span><br><span class="line">    <span class="comment"># 确保安装了 easyfsl!</span></span><br><span class="line">    %cd ..</span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br></pre></td></tr></table></figure>

<p><strong>1. 通过设置随机种子来确保可复现性。</strong></p>
<p>我们将为我们可能使用的所有随机包设置种子，再加上一些其他东西来使 CUDA 具有确定性（参见<a target="_blank" rel="noopener" href="https://pytorch.org/docs/stable/notes/randomness.html">这里</a>）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">random_seed = <span class="number">0</span></span><br><span class="line">np.random.seed(random_seed)</span><br><span class="line">torch.manual_seed(random_seed)</span><br><span class="line">random.seed(random_seed)</span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br></pre></td></tr></table></figure>

<p><strong>2. 为训练集创建数据加载器。</strong></p>
<p>因为它是一个小型数据集，所以我们可以相当快地获得好结果。我将批量大小设置为 128，但请随时根据你的需求进行调整。</p>
<p>请注意，我们没有为训练数据加载器使用 TaskSampler，因为我们不会像在情景训练中那样以任务的形式采样训练数据。我们以正常方式进行。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载 CUB 数据集</span></span><br><span class="line">!make download-cub</span><br><span class="line"><span class="keyword">from</span> easyfsl.datasets <span class="keyword">import</span> CUB</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">n_workers = <span class="number">12</span></span><br><span class="line"></span><br><span class="line">train_set = CUB(split=<span class="string">&quot;train&quot;</span>, training=<span class="literal">True</span>)</span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_set,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    num_workers=n_workers,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    shuffle=<span class="literal">True</span>,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>3. 创建要训练的模型。</strong></p>
<p>这里我们选择了在少样本学习研究中非常常用的 ResNet12。</p>
<p>请注意，EasyFSL 中这些网络的默认设置是没有最后一个全连接层（这对大多数少样本学习方法来说是常见的），但对于经典训练我们需要这个层！我们还强制它输出一个向量，其大小等于训练集中不同类别的数量。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> easyfsl.modules <span class="keyword">import</span> resnet12</span><br><span class="line"></span><br><span class="line">DEVICE = <span class="string">&quot;cuda&quot;</span> <span class="comment"># 设备设置为 CUDA (GPU)</span></span><br><span class="line"></span><br><span class="line">model = resnet12(</span><br><span class="line">    use_fc=<span class="literal">True</span>, <span class="comment"># 设置为 True 表示使用最后的全连接层</span></span><br><span class="line">    num_classes=<span class="built_in">len</span>(<span class="built_in">set</span>(train_set.get_labels())), <span class="comment"># 输出维度 = 训练类别数</span></span><br><span class="line">).to(DEVICE) <span class="comment"># 将模型移至 GPU</span></span><br></pre></td></tr></table></figure>

<p><strong>4. 验证</strong></p>
<p>由于我们训练的是一个模型来执行少样本分类，我们将在少样本任务上进行验证，所以现在我们将使用 TaskSampler。我们任意设置验证任务的形状。理想情况下，你希望在不同形状的任务上进行验证，但我们还没有实现这一点（欢迎贡献！）。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> easyfsl.methods <span class="keyword">import</span> PrototypicalNetworks</span><br><span class="line"><span class="keyword">from</span> easyfsl.samplers <span class="keyword">import</span> TaskSampler</span><br><span class="line"></span><br><span class="line">n_way = <span class="number">5</span>  <span class="comment"># 每个任务 N 类</span></span><br><span class="line">n_shot = <span class="number">5</span>  <span class="comment"># 每类支撑样本数</span></span><br><span class="line">n_query = <span class="number">10</span> <span class="comment"># 每类查询样本数</span></span><br><span class="line">n_validation_tasks = <span class="number">500</span> <span class="comment"># 验证任务数</span></span><br><span class="line"></span><br><span class="line">val_set = CUB(split=<span class="string">&quot;val&quot;</span>, training=<span class="literal">False</span>) <span class="comment"># 验证集</span></span><br><span class="line">val_sampler = TaskSampler(</span><br><span class="line">    val_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_validation_tasks</span><br><span class="line">)</span><br><span class="line">val_loader = DataLoader(</span><br><span class="line">    val_set,</span><br><span class="line">    batch_sampler=val_sampler,</span><br><span class="line">    num_workers=n_workers,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=val_sampler.episodic_collate_fn, <span class="comment"># 使用任务采样器的情景整理函数</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">few_shot_classifier = PrototypicalNetworks(model).to(DEVICE) <span class="comment"># 用主干模型创建原型网络分类器并移至 GPU</span></span><br></pre></td></tr></table></figure>

<h3 id="训练：-1"><a href="#训练：-1" class="headerlink" title="训练："></a>训练：</h3><p>现在让我们定义我们的训练辅助工具！我选择在 200 个周期（epoch）上使用随机梯度下降（SGD），并使用一个在 120 和 160 个周期后将学习率除以 10 的调度器（scheduler）。该策略源自<a target="_blank" rel="noopener" href="https://github.com/kjunelee/MetaOptNet">这个仓库</a>。</p>
<p><strong>1. 使用 TensorBoard 观察训练曲线。</strong></p>
<p>另外一点：我们像在情景训练笔记本中一样进行 200 个周期，但请记住，经典训练中的一个周期意味着遍历数据集的 6000 张图像一次，而在情景训练中，一个周期是任意数量的情景（episode）。在情景训练笔记本中，一个周期是 500 个情景，每个情景是 5-way, 5-shot, 10-query 任务，因此是 37500 张图像。TL;DR 你可能需要监控你的训练，并在必要时增加周期数。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.optim <span class="keyword">import</span> SGD, Optimizer</span><br><span class="line"><span class="keyword">from</span> torch.optim.lr_scheduler <span class="keyword">import</span> MultiStepLR</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"></span><br><span class="line">LOSS_FUNCTION = nn.CrossEntropyLoss() <span class="comment"># 损失函数：交叉熵损失</span></span><br><span class="line"></span><br><span class="line">n_epochs = <span class="number">200</span> <span class="comment"># 总周期数</span></span><br><span class="line">scheduler_milestones = [<span class="number">150</span>, <span class="number">180</span>] <span class="comment"># 学习率调整的阶段点</span></span><br><span class="line">scheduler_gamma = <span class="number">0.1</span> <span class="comment"># 学习率衰减因子</span></span><br><span class="line">learning_rate = <span class="number">1e-01</span> <span class="comment"># 初始学习率</span></span><br><span class="line">tb_logs_dir = Path(<span class="string">&quot;.&quot;</span>) <span class="comment"># TensorBoard 日志目录</span></span><br><span class="line"></span><br><span class="line">train_optimizer = SGD( <span class="comment"># SGD 优化器</span></span><br><span class="line">    model.parameters(), lr=learning_rate, momentum=<span class="number">0.9</span>, weight_decay=<span class="number">5e-4</span></span><br><span class="line">)</span><br><span class="line">train_scheduler = MultiStepLR( <span class="comment"># 多步学习率调度器</span></span><br><span class="line">    train_optimizer,</span><br><span class="line">    milestones=scheduler_milestones,</span><br><span class="line">    gamma=scheduler_gamma,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">tb_writer = SummaryWriter(log_dir=<span class="built_in">str</span>(tb_logs_dir)) <span class="comment"># TensorBoard 写入器</span></span><br></pre></td></tr></table></figure>

<p><strong>2. 定义了执行一个训练周期的函数。</strong></p>
<p>使用 tqdm 在日志中实时监控训练进度。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">training_epoch</span>(<span class="params">model_: nn.Module, data_loader: DataLoader, optimizer: Optimizer</span>):</span><br><span class="line">    all_loss = [] <span class="comment"># 存储每个批次的损失</span></span><br><span class="line">    model_.train() <span class="comment"># 设置模型为训练模式</span></span><br><span class="line">    <span class="keyword">with</span> tqdm(data_loader, total=<span class="built_in">len</span>(data_loader), desc=<span class="string">&quot;Training&quot;</span>) <span class="keyword">as</span> tqdm_train: <span class="comment"># 使用进度条</span></span><br><span class="line">        <span class="keyword">for</span> images, labels <span class="keyword">in</span> tqdm_train:</span><br><span class="line">            optimizer.zero_grad() <span class="comment"># 梯度清零</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 前向传播，计算损失</span></span><br><span class="line">            loss = LOSS_FUNCTION(model_(images.to(DEVICE)), labels.to(DEVICE))</span><br><span class="line">            loss.backward() <span class="comment"># 反向传播</span></span><br><span class="line">            optimizer.step() <span class="comment"># 更新参数</span></span><br><span class="line"></span><br><span class="line">            all_loss.append(loss.item()) <span class="comment"># 记录当前批次损失</span></span><br><span class="line"></span><br><span class="line">            tqdm_train.set_postfix(loss=mean(all_loss)) <span class="comment"># 更新进度条显示平均损失</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> mean(all_loss) <span class="comment"># 返回整个周期的平均损失</span></span><br></pre></td></tr></table></figure>

<p><strong>3. 开始训练</strong></p>
<ul>
<li>我们每 10 个周期验证一次（你可以设置更低的频率），因为一个训练周期比 500 个少样本任务快得多，我们不希望验证成为训练过程的瓶颈。</li>
<li>我们还添加了记录在验证集上表现最佳模型状态的代码。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> easyfsl.utils <span class="keyword">import</span> evaluate <span class="comment"># 导入 EasyFSL 的评估函数</span></span><br><span class="line"></span><br><span class="line">best_state = model.state_dict() <span class="comment"># 保存最佳模型状态</span></span><br><span class="line">best_validation_accuracy = <span class="number">0.0</span> <span class="comment"># 最佳验证准确率</span></span><br><span class="line">validation_frequency = <span class="number">10</span> <span class="comment"># 验证频率（每 validation_frequency 个周期验证一次）</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(n_epochs):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch&#125;</span>&quot;</span>) <span class="comment"># 打印当前周期</span></span><br><span class="line">    average_loss = training_epoch(model, train_loader, train_optimizer) <span class="comment"># 训练一个周期，得到平均损失</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> epoch % validation_frequency == validation_frequency - <span class="number">1</span>: <span class="comment"># 达到验证点</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 我们使用 EasyFSL 的 ResNet 中这个非常方便的方法来指定</span></span><br><span class="line">        <span class="comment"># 模型在验证期间不应使用其最后一个全连接层。</span></span><br><span class="line">        model.set_use_fc(<span class="literal">False</span>)</span><br><span class="line">        validation_accuracy = evaluate( <span class="comment"># 在验证集上评估少样本分类器</span></span><br><span class="line">            few_shot_classifier, val_loader, device=DEVICE, tqdm_prefix=<span class="string">&quot;Validation&quot;</span></span><br><span class="line">        )</span><br><span class="line">        model.set_use_fc(<span class="literal">True</span>) <span class="comment"># 验证后恢复使用全连接层（用于后续训练）</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> validation_accuracy &gt; best_validation_accuracy: <span class="comment"># 找到新的最佳模型</span></span><br><span class="line">            best_validation_accuracy = validation_accuracy</span><br><span class="line">            best_state = copy.deepcopy(few_shot_classifier.state_dict()) <span class="comment"># 深拷贝当前最佳状态</span></span><br><span class="line">            <span class="comment"># state_dict() 返回对仍在演变的模型状态的引用，所以我们进行深拷贝</span></span><br><span class="line">            <span class="comment"># 参考：https://pytorch.org/tutorials/beginner/saving_loading_models</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;叮叮叮！我们找到了一个新的最佳模型！&quot;</span>)</span><br><span class="line"></span><br><span class="line">        tb_writer.add_scalar(<span class="string">&quot;Val/acc&quot;</span>, validation_accuracy, epoch) <span class="comment"># 记录验证准确率到 TensorBoard</span></span><br><span class="line"></span><br><span class="line">    tb_writer.add_scalar(<span class="string">&quot;Train/loss&quot;</span>, average_loss, epoch) <span class="comment"># 记录训练损失到 TensorBoard</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 通知调度器我们完成了一个周期</span></span><br><span class="line">    <span class="comment"># 这样它就知道何时降低学习率</span></span><br><span class="line">    train_scheduler.step()</span><br></pre></td></tr></table></figure>

<p><strong>4. 如果需要，可以检索最佳模型的状态。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict(best_state) <span class="comment"># 加载最佳模型状态</span></span><br></pre></td></tr></table></figure>

<h3 id="评估：-1"><a href="#评估：-1" class="headerlink" title="评估："></a>评估：</h3><p><strong>1. 获取测试数据</strong></p>
<p>请注意，我们将在与验证时相同形状的任务上进行评估。这是一种不当做法（malicious practice），因为这意味着我们在训练期间使用了关于评估任务的先验信息。不过，这仍然比情景训练的弊端要小。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">n_test_tasks = <span class="number">1000</span> <span class="comment"># 测试任务数</span></span><br><span class="line"></span><br><span class="line">test_set = CUB(split=<span class="string">&quot;test&quot;</span>, training=<span class="literal">False</span>) <span class="comment"># 测试集</span></span><br><span class="line">test_sampler = TaskSampler( <span class="comment"># 测试任务采样器</span></span><br><span class="line">    test_set, n_way=n_way, n_shot=n_shot, n_query=n_query, n_tasks=n_test_tasks</span><br><span class="line">)</span><br><span class="line">test_loader = DataLoader( <span class="comment"># 测试数据加载器</span></span><br><span class="line">    test_set,</span><br><span class="line">    batch_sampler=test_sampler,</span><br><span class="line">    num_workers=n_workers,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=test_sampler.episodic_collate_fn,</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p><strong>2. 我们使用训练好的 ResNet 作为主干网络实例化一个少样本分类器，并在测试数据上运行它。</strong></p>
<p>为了保持一致性，我们继续使用原型网络，但此时你基本上可以使用任何不需要额外可训练参数的少样本分类器。</p>
<p>像在验证期间一样，我们需要告诉我们的 ResNet 不要使用其最后一个全连接层。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.set_use_fc(<span class="literal">False</span>) <span class="comment"># 禁用全连接层（使用主干网络特征）</span></span><br><span class="line"></span><br><span class="line">accuracy = evaluate(few_shot_classifier, test_loader, device=DEVICE) <span class="comment"># 在测试集上评估</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;平均准确率 : <span class="subst">&#123;(<span class="number">100</span> * accuracy):<span class="number">.2</span>f&#125;</span> %&quot;</span>) <span class="comment"># 打印平均准确率</span></span><br></pre></td></tr></table></figure>

<h3 id="完整代码实例-2"><a href="#完整代码实例-2" class="headerlink" title="完整代码实例"></a>完整代码实例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">经典训练小样本学习模型项目</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">本代码演示了如何使用经典训练（非情景训练）方法训练一个小样本学习模型。</span></span><br><span class="line"><span class="string">我们使用CUB-200鸟类数据集，训练一个ResNet12模型，并在测试阶段使用原型网络(Prototypical Networks)进行评估。</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">关键步骤：</span></span><br><span class="line"><span class="string">1. 环境设置和依赖安装</span></span><br><span class="line"><span class="string">2. 数据加载和预处理</span></span><br><span class="line"><span class="string">3. 模型定义（带全连接层的ResNet12）</span></span><br><span class="line"><span class="string">4. 训练循环（使用交叉熵损失）</span></span><br><span class="line"><span class="string">5. 验证（使用少样本任务）</span></span><br><span class="line"><span class="string">6. 测试评估</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">作者：AI助手</span></span><br><span class="line"><span class="string">日期：2023年11月</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第一部分：环境设置和依赖安装</span></span><br><span class="line"><span class="comment"># ====================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否在Google Colab环境中运行</span></span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="keyword">import</span> google.colab</span><br><span class="line">    colab = <span class="literal">True</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;检测到在Google Colab环境中运行&quot;</span>)</span><br><span class="line"><span class="keyword">except</span>:</span><br><span class="line">    colab = <span class="literal">False</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;在本地环境中运行&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果在Colab中运行，需要克隆仓库并安装依赖</span></span><br><span class="line"><span class="keyword">if</span> colab:</span><br><span class="line">    <span class="comment"># 克隆EasyFSL仓库</span></span><br><span class="line">    !git clone https://github.com/sicara/easy-few-shot-learning</span><br><span class="line">    %cd easy-few-shot-learning</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 安装必要的Python包</span></span><br><span class="line">    !pip install -r requirements.txt</span><br><span class="line">    !pip install .</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 设置工作目录</span></span><br><span class="line">    <span class="keyword">import</span> os</span><br><span class="line">    os.chdir(<span class="string">&#x27;/content/easy-few-shot-learning&#x27;</span>)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="comment"># 在本地运行，确保已安装easyfsl</span></span><br><span class="line">    <span class="comment"># 提示：可以使用 pip install easyfsl 安装</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;请确保已安装easyfsl库：pip install easyfsl&quot;</span>)</span><br><span class="line">    %cd ..  <span class="comment"># 切换到项目根目录（根据实际情况调整）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 导入必要的库</span></span><br><span class="line"><span class="keyword">import</span> copy</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">from</span> pathlib <span class="keyword">import</span> Path</span><br><span class="line"><span class="keyword">import</span> random</span><br><span class="line"><span class="keyword">from</span> statistics <span class="keyword">import</span> mean</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torch <span class="keyword">import</span> nn, optim</span><br><span class="line"><span class="keyword">from</span> torch.utils.data <span class="keyword">import</span> DataLoader</span><br><span class="line"><span class="keyword">from</span> torch.utils.tensorboard <span class="keyword">import</span> SummaryWriter</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第二部分：设置随机种子确保可复现性</span></span><br><span class="line"><span class="comment"># ====================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置随机种子 - 这是机器学习研究中的最佳实践</span></span><br><span class="line">random_seed = <span class="number">42</span>  <span class="comment"># 可以更改为任何整数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;设置随机种子: <span class="subst">&#123;random_seed&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置各种随机数生成器的种子</span></span><br><span class="line">np.random.seed(random_seed)</span><br><span class="line">torch.manual_seed(random_seed)</span><br><span class="line">random.seed(random_seed)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置CuDNN以获得可重复的结果（可能会降低性能）</span></span><br><span class="line">torch.backends.cudnn.deterministic = <span class="literal">True</span></span><br><span class="line">torch.backends.cudnn.benchmark = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 第三部分：数据加载和预处理</span></span><br><span class="line"><span class="comment"># ====================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查CUDA可用性并设置设备</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;使用设备: <span class="subst">&#123;device&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载CUB-200-2011数据集</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n正在下载和准备CUB数据集...&quot;</span>)</span><br><span class="line"><span class="keyword">from</span> easyfsl.datasets <span class="keyword">import</span> CUB</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建数据集目录</span></span><br><span class="line">data_root = Path(<span class="string">&quot;data&quot;</span>)</span><br><span class="line">data_root.mkdir(exist_ok=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练集 - 用于经典训练</span></span><br><span class="line">train_set = CUB(</span><br><span class="line">    root=data_root,</span><br><span class="line">    split=<span class="string">&quot;train&quot;</span>,</span><br><span class="line">    training=<span class="literal">True</span>,  <span class="comment"># 启用训练模式转换</span></span><br><span class="line">    download=<span class="literal">True</span>   <span class="comment"># 确保下载数据集</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练数据加载器 - 使用标准批处理而不是情景采样</span></span><br><span class="line">batch_size = <span class="number">32</span>  <span class="comment"># 根据GPU内存调整</span></span><br><span class="line">num_workers = <span class="number">4</span>  <span class="comment"># 根据CPU核心数调整</span></span><br><span class="line"></span><br><span class="line">train_loader = DataLoader(</span><br><span class="line">    train_set,</span><br><span class="line">    batch_size=batch_size,</span><br><span class="line">    shuffle=<span class="literal">True</span>,  <span class="comment"># 训练时打乱数据很重要</span></span><br><span class="line">    num_workers=num_workers,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,  <span class="comment"># 加速数据转移到GPU</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;训练集: <span class="subst">&#123;<span class="built_in">len</span>(train_set)&#125;</span>张图片, <span class="subst">&#123;<span class="built_in">len</span>(train_set.get_labels())&#125;</span>个类别&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 验证集 - 用于少样本任务验证</span></span><br><span class="line">val_set = CUB(</span><br><span class="line">    root=data_root,</span><br><span class="line">    split=<span class="string">&quot;val&quot;</span>,</span><br><span class="line">    training=<span class="literal">False</span>,  <span class="comment"># 验证时不需要数据增强</span></span><br><span class="line">    download=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试集 - 用于最终评估</span></span><br><span class="line">test_set = CUB(</span><br><span class="line">    root=data_root,</span><br><span class="line">    split=<span class="string">&quot;test&quot;</span>,</span><br><span class="line">    training=<span class="literal">False</span>,</span><br><span class="line">    download=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;验证集: <span class="subst">&#123;<span class="built_in">len</span>(val_set)&#125;</span>张图片&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试集: <span class="subst">&#123;<span class="built_in">len</span>(test_set)&#125;</span>张图片&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第四部分：模型定义</span></span><br><span class="line"><span class="comment"># ====================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> easyfsl.modules <span class="keyword">import</span> resnet12</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建模型 - 使用带全连接层的ResNet12</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n创建模型...&quot;</span>)</span><br><span class="line">model = resnet12(</span><br><span class="line">    use_fc=<span class="literal">True</span>,  <span class="comment"># 经典训练需要全连接层</span></span><br><span class="line">    num_classes=<span class="built_in">len</span>(<span class="built_in">set</span>(train_set.get_labels())),  <span class="comment"># 输出层大小=训练类别数</span></span><br><span class="line">).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印模型摘要</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;模型架构:&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(model)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算模型参数数量</span></span><br><span class="line">total_params = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters())</span><br><span class="line">trainable_params = <span class="built_in">sum</span>(p.numel() <span class="keyword">for</span> p <span class="keyword">in</span> model.parameters() <span class="keyword">if</span> p.requires_grad)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;总参数: <span class="subst">&#123;total_params:,&#125;</span> | 可训练参数: <span class="subst">&#123;trainable_params:,&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第五部分：训练准备</span></span><br><span class="line"><span class="comment"># ====================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义损失函数和优化器</span></span><br><span class="line">criterion = nn.CrossEntropyLoss()  <span class="comment"># 交叉熵损失 - 用于分类任务</span></span><br><span class="line">learning_rate = <span class="number">0.01</span>  <span class="comment"># 初始学习率</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用带动量的SGD优化器</span></span><br><span class="line">optimizer = optim.SGD(</span><br><span class="line">    model.parameters(), </span><br><span class="line">    lr=learning_rate,</span><br><span class="line">    momentum=<span class="number">0.9</span>,  <span class="comment"># 动量帮助加速收敛</span></span><br><span class="line">    weight_decay=<span class="number">5e-4</span>  <span class="comment"># L2正则化防止过拟合</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 学习率调度器 - 训练过程中调整学习率</span></span><br><span class="line">scheduler = optim.lr_scheduler.MultiStepLR(</span><br><span class="line">    optimizer,</span><br><span class="line">    milestones=[<span class="number">100</span>, <span class="number">150</span>],  <span class="comment"># 在这些epoch降低学习率</span></span><br><span class="line">    gamma=<span class="number">0.1</span>  <span class="comment"># 每次降低10倍</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置TensorBoard记录</span></span><br><span class="line">log_dir = Path(<span class="string">&quot;logs/classical_training&quot;</span>)</span><br><span class="line">log_dir.mkdir(parents=<span class="literal">True</span>, exist_ok=<span class="literal">True</span>)</span><br><span class="line">writer = SummaryWriter(log_dir=<span class="built_in">str</span>(log_dir))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练参数</span></span><br><span class="line">num_epochs = <span class="number">50</span>  <span class="comment"># 总训练轮数</span></span><br><span class="line">validation_freq = <span class="number">5</span>  <span class="comment"># 每5个epoch验证一次</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n开始训练: <span class="subst">&#123;num_epochs&#125;</span>个epoch, 每<span class="subst">&#123;validation_freq&#125;</span>个epoch验证一次&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第六部分：训练循环</span></span><br><span class="line"><span class="comment"># ====================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 用于存储最佳模型</span></span><br><span class="line">best_val_accuracy = <span class="number">0.0</span></span><br><span class="line">best_model_state = <span class="literal">None</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练循环</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(num_epochs):</span><br><span class="line">    start_time = time.time()</span><br><span class="line">    model.train()  <span class="comment"># 设置模型为训练模式</span></span><br><span class="line">    running_loss = <span class="number">0.0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    total = <span class="number">0</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 使用tqdm创建进度条</span></span><br><span class="line">    train_loop = tqdm(train_loader, desc=<span class="string">f&quot;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> images, labels <span class="keyword">in</span> train_loop:</span><br><span class="line">        <span class="comment"># 将数据移至设备</span></span><br><span class="line">        images = images.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 前向传播</span></span><br><span class="line">        outputs = model(images)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 反向传播和优化</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 统计信息</span></span><br><span class="line">        running_loss += loss.item()</span><br><span class="line">        _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">        total += labels.size(<span class="number">0</span>)</span><br><span class="line">        correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 更新进度条</span></span><br><span class="line">        avg_loss = running_loss / (train_loop.n + <span class="number">1</span>)</span><br><span class="line">        accuracy = <span class="number">100</span> * correct / total</span><br><span class="line">        train_loop.set_postfix(loss=avg_loss, acc=accuracy)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 计算平均损失和准确率</span></span><br><span class="line">    epoch_loss = running_loss / <span class="built_in">len</span>(train_loader)</span><br><span class="line">    epoch_acc = <span class="number">100</span> * correct / total</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 记录到TensorBoard</span></span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;Train/Loss&#x27;</span>, epoch_loss, epoch)</span><br><span class="line">    writer.add_scalar(<span class="string">&#x27;Train/Accuracy&#x27;</span>, epoch_acc, epoch)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 学习率调度器步进</span></span><br><span class="line">    scheduler.step()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 验证阶段</span></span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % validation_freq == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;\n开始验证...&quot;</span>)</span><br><span class="line">        <span class="keyword">from</span> easyfsl.methods <span class="keyword">import</span> PrototypicalNetworks</span><br><span class="line">        <span class="keyword">from</span> easyfsl.samplers <span class="keyword">import</span> TaskSampler</span><br><span class="line">        <span class="keyword">from</span> easyfsl.utils <span class="keyword">import</span> evaluate</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 设置少样本任务参数</span></span><br><span class="line">        n_way = <span class="number">5</span>    <span class="comment"># 每个任务5个类别</span></span><br><span class="line">        n_shot = <span class="number">5</span>   <span class="comment"># 每类5个支持样本</span></span><br><span class="line">        n_query = <span class="number">15</span> <span class="comment"># 每类15个查询样本</span></span><br><span class="line">        n_tasks = <span class="number">100</span> <span class="comment"># 验证任务数量</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建任务采样器</span></span><br><span class="line">        val_sampler = TaskSampler(</span><br><span class="line">            val_set, </span><br><span class="line">            n_way=n_way, </span><br><span class="line">            n_shot=n_shot, </span><br><span class="line">            n_query=n_query, </span><br><span class="line">            n_tasks=n_tasks</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建验证数据加载器</span></span><br><span class="line">        val_loader = DataLoader(</span><br><span class="line">            val_set,</span><br><span class="line">            batch_sampler=val_sampler,</span><br><span class="line">            num_workers=num_workers,</span><br><span class="line">            pin_memory=<span class="literal">True</span>,</span><br><span class="line">            collate_fn=val_sampler.episodic_collate_fn,</span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 创建原型网络分类器</span></span><br><span class="line">        model.<span class="built_in">eval</span>()</span><br><span class="line">        model.set_use_fc(<span class="literal">False</span>)  <span class="comment"># 禁用全连接层，使用特征提取器</span></span><br><span class="line">        proto_net = PrototypicalNetworks(model).to(device)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 评估模型</span></span><br><span class="line">        val_accuracy = evaluate(</span><br><span class="line">            proto_net, </span><br><span class="line">            val_loader, </span><br><span class="line">            device=device,</span><br><span class="line">            tqdm_prefix=<span class="string">f&quot;验证 Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>&quot;</span></span><br><span class="line">        )</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 记录验证准确率</span></span><br><span class="line">        writer.add_scalar(<span class="string">&#x27;Val/Accuracy&#x27;</span>, val_accuracy, epoch)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 检查是否是最佳模型</span></span><br><span class="line">        <span class="keyword">if</span> val_accuracy &gt; best_val_accuracy:</span><br><span class="line">            best_val_accuracy = val_accuracy</span><br><span class="line">            best_model_state = copy.deepcopy(model.state_dict())</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">f&quot;🎉 发现新最佳模型! 验证准确率: <span class="subst">&#123;val_accuracy*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 恢复全连接层用于训练</span></span><br><span class="line">        model.set_use_fc(<span class="literal">True</span>)</span><br><span class="line">        model.train()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 打印epoch统计信息</span></span><br><span class="line">    epoch_time = time.time() - start_time</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;Epoch <span class="subst">&#123;epoch+<span class="number">1</span>&#125;</span>/<span class="subst">&#123;num_epochs&#125;</span> - 耗时: <span class="subst">&#123;epoch_time:<span class="number">.1</span>f&#125;</span>s&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;  训练损失: <span class="subst">&#123;epoch_loss:<span class="number">.4</span>f&#125;</span>, 训练准确率: <span class="subst">&#123;epoch_acc:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> (epoch + <span class="number">1</span>) % validation_freq == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;  验证准确率: <span class="subst">&#123;val_accuracy*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 保存最佳模型</span></span><br><span class="line"><span class="keyword">if</span> best_model_state <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    torch.save(best_model_state, <span class="string">&#x27;best_model.pth&#x27;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;✅ 最佳模型已保存为 &#x27;best_model.pth&#x27;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第七部分：测试评估</span></span><br><span class="line"><span class="comment"># ====================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n开始测试评估...&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载最佳模型</span></span><br><span class="line"><span class="keyword">if</span> best_model_state <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">    model.load_state_dict(best_model_state)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;已加载最佳模型进行测试&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置测试任务参数</span></span><br><span class="line">n_way = <span class="number">5</span>     <span class="comment"># 每个任务5个类别</span></span><br><span class="line">n_shot = <span class="number">5</span>    <span class="comment"># 每类5个支持样本</span></span><br><span class="line">n_query = <span class="number">15</span>  <span class="comment"># 每类15个查询样本</span></span><br><span class="line">n_tasks = <span class="number">600</span> <span class="comment"># 测试任务数量（推荐至少600个任务以获得可靠估计）</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建任务采样器</span></span><br><span class="line">test_sampler = TaskSampler(</span><br><span class="line">    test_set, </span><br><span class="line">    n_way=n_way, </span><br><span class="line">    n_shot=n_shot, </span><br><span class="line">    n_query=n_query, </span><br><span class="line">    n_tasks=n_tasks</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建测试数据加载器</span></span><br><span class="line">test_loader = DataLoader(</span><br><span class="line">    test_set,</span><br><span class="line">    batch_sampler=test_sampler,</span><br><span class="line">    num_workers=num_workers,</span><br><span class="line">    pin_memory=<span class="literal">True</span>,</span><br><span class="line">    collate_fn=test_sampler.episodic_collate_fn,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建原型网络分类器</span></span><br><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">model.set_use_fc(<span class="literal">False</span>)  <span class="comment"># 禁用全连接层</span></span><br><span class="line">proto_net = PrototypicalNetworks(model).to(device)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 评估模型</span></span><br><span class="line"><span class="keyword">from</span> easyfsl.utils <span class="keyword">import</span> evaluate</span><br><span class="line"></span><br><span class="line">test_accuracy = evaluate(</span><br><span class="line">    proto_net, </span><br><span class="line">    test_loader, </span><br><span class="line">    device=device,</span><br><span class="line">    tqdm_prefix=<span class="string">&quot;测试&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 打印最终结果</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n<span class="subst">&#123;<span class="string">&#x27;=&#x27;</span>*<span class="number">50</span>&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;测试结果 (<span class="subst">&#123;n_tasks&#125;</span>个 <span class="subst">&#123;n_way&#125;</span>-way <span class="subst">&#123;n_shot&#125;</span>-shot 任务):&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;平均准确率: <span class="subst">&#123;test_accuracy*<span class="number">100</span>:<span class="number">.2</span>f&#125;</span>%&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;=&#x27;</span>*<span class="number">50</span>&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 第八部分：可视化支持集和查询集示例</span></span><br><span class="line"><span class="comment"># ====================================================================================</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 可视化一个任务的支持集和查询集</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">denormalize</span>(<span class="params">image</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;将归一化的图像反归一化以便显示&quot;&quot;&quot;</span></span><br><span class="line">    mean = torch.tensor([<span class="number">0.485</span>, <span class="number">0.456</span>, <span class="number">0.406</span>]).view(<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    std = torch.tensor([<span class="number">0.229</span>, <span class="number">0.224</span>, <span class="number">0.225</span>]).view(<span class="number">3</span>, <span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> image * std + mean</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">show_task_support_query</span>(<span class="params">loader, num_examples=<span class="number">5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;显示一个任务的支持集和查询集示例&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 获取一个批次（一个任务）</span></span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> loader:</span><br><span class="line">        support_images, support_labels, query_images, query_labels, _ = batch</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 选择前num_examples个类别</span></span><br><span class="line">    unique_classes = torch.unique(support_labels)[:num_examples]</span><br><span class="line">    </span><br><span class="line">    fig, axes = plt.subplots(num_examples, <span class="number">2</span>, figsize=(<span class="number">10</span>, num_examples*<span class="number">3</span>))</span><br><span class="line">    fig.suptitle(<span class="string">f&quot;<span class="subst">&#123;n_way&#125;</span>-Way <span class="subst">&#123;n_shot&#125;</span>-Shot 任务示例&quot;</span>, fontsize=<span class="number">16</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> i, cls <span class="keyword">in</span> <span class="built_in">enumerate</span>(unique_classes):</span><br><span class="line">        <span class="comment"># 获取当前类别的支持图像</span></span><br><span class="line">        cls_support_indices = torch.where(support_labels == cls)[<span class="number">0</span>][:n_shot]</span><br><span class="line">        cls_support_images = support_images[cls_support_indices]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 获取当前类别的查询图像</span></span><br><span class="line">        cls_query_indices = torch.where(query_labels == cls)[<span class="number">0</span>][:<span class="number">1</span>]  <span class="comment"># 只取一个查询图像</span></span><br><span class="line">        cls_query_image = query_images[cls_query_indices][<span class="number">0</span>]</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示支持图像</span></span><br><span class="line">        support_grid = torchvision.utils.make_grid(</span><br><span class="line">            [denormalize(img) <span class="keyword">for</span> img <span class="keyword">in</span> cls_support_images],</span><br><span class="line">            nrow=n_shot</span><br><span class="line">        )</span><br><span class="line">        axes[i, <span class="number">0</span>].imshow(support_grid.permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">        axes[i, <span class="number">0</span>].set_title(<span class="string">f&quot;类别 <span class="subst">&#123;cls.item()&#125;</span> - 支持集 (<span class="subst">&#123;n_shot&#125;</span>张图像)&quot;</span>)</span><br><span class="line">        axes[i, <span class="number">0</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 显示查询图像</span></span><br><span class="line">        axes[i, <span class="number">1</span>].imshow(denormalize(cls_query_image).permute(<span class="number">1</span>, <span class="number">2</span>, <span class="number">0</span>))</span><br><span class="line">        axes[i, <span class="number">1</span>].set_title(<span class="string">f&quot;类别 <span class="subst">&#123;cls.item()&#125;</span> - 查询图像&quot;</span>)</span><br><span class="line">        axes[i, <span class="number">1</span>].axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    </span><br><span class="line">    plt.tight_layout()</span><br><span class="line">    plt.savefig(<span class="string">&#x27;task_example.png&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 显示一个任务示例</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n显示一个少样本任务示例...&quot;</span>)</span><br><span class="line">show_task_support_query(test_loader)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 关闭TensorBoard写入器</span></span><br><span class="line">writer.close()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练完成!&quot;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>项目说明</strong></p>
<ol>
<li><strong>经典训练 vs 情景训练</strong>：<ul>
<li>经典训练：使用标准的交叉熵损失在所有训练类别上训练模型</li>
<li>情景训练：以少样本任务的形式进行训练</li>
</ul>
</li>
<li><strong>小样本学习</strong>：<ul>
<li>N-way K-shot：每个任务包含N个类别，每个类别K个样本（支持集）</li>
<li>查询集：用于评估模型性能的样本</li>
</ul>
</li>
<li><strong>模型架构</strong>：<ul>
<li>ResNet12作为特征提取器（主干网络）</li>
<li>训练时添加全连接层进行分类</li>
<li>测试时移除全连接层，使用特征提取器</li>
</ul>
</li>
</ol>
<p><strong>代码结构</strong></p>
<ol>
<li><strong>环境设置</strong>：<ul>
<li>自动检测是否在Colab中运行</li>
<li>设置随机种子确保可复现性</li>
</ul>
</li>
<li><strong>数据准备</strong>：<ul>
<li>下载CUB-200鸟类数据集</li>
<li>创建训练、验证和测试集</li>
<li>不同的数据加载器：训练使用标准批处理，验证和测试使用情景任务</li>
</ul>
</li>
<li><strong>模型定义</strong>：<ul>
<li>使用ResNet12作为主干网络</li>
<li>训练时添加全连接层</li>
<li>计算并显示模型参数数量</li>
</ul>
</li>
<li><strong>训练配置</strong>：<ul>
<li>交叉熵损失函数</li>
<li>SGD优化器（带动量和权重衰减）</li>
<li>学习率调度器</li>
<li>TensorBoard日志记录</li>
</ul>
</li>
<li><strong>训练循环</strong>：<ul>
<li>标准训练过程（前向传播、损失计算、反向传播）</li>
<li>定期验证（使用原型网络）</li>
<li>保存最佳模型</li>
</ul>
</li>
<li><strong>测试评估</strong>：<ul>
<li>在测试集上评估模型性能</li>
<li>使用600个少样本任务进行可靠评估</li>
</ul>
</li>
<li><strong>可视化</strong>：<ul>
<li>展示少样本任务的示例（支持集和查询集）</li>
</ul>
</li>
</ol>
<p><strong>运行说明</strong></p>
<ol>
<li><strong>依赖安装</strong>：<ul>
<li>需要安装PyTorch和EasyFSL库</li>
<li>在Colab中会自动安装所需依赖</li>
<li>本地运行：<code>pip install torch easyfsl tqdm tensorboard</code></li>
</ul>
</li>
<li><strong>数据集</strong>：<ul>
<li>代码会自动下载CUB-200数据集</li>
<li>数据集大小：约1.1GB</li>
</ul>
</li>
<li><strong>训练时间</strong>：<ul>
<li>在Colab的免费GPU上：约1-2小时</li>
<li>在本地RTX 3080上：约30-45分钟</li>
</ul>
</li>
<li><strong>调整参数</strong>：<ul>
<li><code>num_epochs</code>：训练轮数</li>
<li><code>batch_size</code>：根据GPU内存调整</li>
<li><code>n_way</code>, <code>n_shot</code>：少样本任务参数</li>
</ul>
</li>
</ol>
<p><strong>预期结果</strong></p>
<p>经过50个epoch的训练后，模型在5-way 5-shot任务上的测试准确率应达到60-70%。最终结果会因随机种子和硬件不同而略有差异。</p>
<hr>
<h2 id="Episodic-vs-Classical"><a href="#Episodic-vs-Classical" class="headerlink" title="Episodic vs Classical"></a>Episodic vs Classical</h2><p><strong>情景训练 vs 经典训练对比表</strong></p>
<table>
<thead>
<tr>
<th align="left"><strong>对比维度</strong></th>
<th align="left"><strong>情景训练 (Episodic Training)</strong></th>
<th align="left"><strong>经典训练 (Classical Training)</strong></th>
</tr>
</thead>
<tbody><tr>
<td align="left"><strong>核心思想</strong></td>
<td align="left">模拟测试时的少样本任务形式进行训练</td>
<td align="left">使用标准的监督学习方式训练模型</td>
</tr>
<tr>
<td align="left"><strong>训练过程</strong></td>
<td align="left">以”任务”（episode）为单位： 每个任务包含N个类，每类K个支持样本和Q个查询样本</td>
<td align="left">以”批次”（batch）为单位： 每个批次包含来自多个类的样本，不特别区分支持&#x2F;查询集</td>
</tr>
<tr>
<td align="left"><strong>损失函数</strong></td>
<td align="left">任务级别的损失（如原型损失、关系损失）</td>
<td align="left">样本级别的标准交叉熵损失</td>
</tr>
<tr>
<td align="left"><strong>训练目标</strong></td>
<td align="left">直接优化模型在少样本任务上的表现</td>
<td align="left">优化模型在标准分类任务上的表现</td>
</tr>
<tr>
<td align="left"><strong>模型输出</strong></td>
<td align="left">训练时不使用分类头，直接输出特征向量</td>
<td align="left">训练时使用全连接层作为分类头</td>
</tr>
<tr>
<td align="left"><strong>数据组织</strong></td>
<td align="left">需要特殊的数据采样器（TaskSampler）</td>
<td align="left">使用标准数据加载器（DataLoader）</td>
</tr>
<tr>
<td align="left"><strong>训练效率</strong></td>
<td align="left">较慢：每个任务需要多次前向传播和元优化</td>
<td align="left">较快：标准的批处理训练</td>
</tr>
<tr>
<td align="left"><strong>训练稳定性</strong></td>
<td align="left">波动较大：每个任务难度不同导致损失波动</td>
<td align="left">相对稳定：损失曲线平滑</td>
</tr>
<tr>
<td align="left"><strong>测试兼容性</strong></td>
<td align="left">特定于训练时使用的N-way K-shot设置</td>
<td align="left">通用：可与任何少样本分类方法配合使用</td>
</tr>
<tr>
<td align="left"><strong>实际应用性</strong></td>
<td align="left">较低：需要预知测试任务结构</td>
<td align="left">较高：更符合实际部署场景</td>
</tr>
<tr>
<td align="left"><strong>训练难度</strong></td>
<td align="left">较难：需要设计有效的情景采样策略</td>
<td align="left">较简单：使用标准训练流程</td>
</tr>
<tr>
<td align="left"><strong>过拟合风险</strong></td>
<td align="left">较低：通过多样化任务增强泛化能力</td>
<td align="left">较高：可能对训练类别过拟合</td>
</tr>
<tr>
<td align="left"><strong>计算资源</strong></td>
<td align="left">较高：需要更多内存存储任务上下文</td>
<td align="left">较低：标准训练资源需求</td>
</tr>
<tr>
<td align="left"><strong>代码复杂度</strong></td>
<td align="left">较高：需要实现任务采样和元训练循环</td>
<td align="left">较低：使用标准训练框架</td>
</tr>
<tr>
<td align="left"><strong>典型方法</strong></td>
<td align="left">Prototypical Networks Matching Networks MAML</td>
<td align="left">带特征提取器的分类模型 + 测试时使用少样本分类器</td>
</tr>
<tr>
<td align="left"><strong>适用场景</strong></td>
<td align="left">研究实验 特定任务结构的应用</td>
<td align="left">实际部署 需要灵活测试设置的场景</td>
</tr>
<tr>
<td align="left"><strong>主要优势</strong></td>
<td align="left">直接优化少样本性能 任务多样性增强泛化</td>
<td align="left">训练简单高效 与现有框架兼容性好 测试时方法灵活</td>
</tr>
<tr>
<td align="left"><strong>主要劣势</strong></td>
<td align="left">需要预知测试任务结构 训练过程复杂</td>
<td align="left">可能对训练类别过拟合 训练目标与测试目标不一致</td>
</tr>
<tr>
<td align="left"><strong>准确率表现</strong></td>
<td align="left">在匹配的任务结构上表现更好</td>
<td align="left">在通用任务上表现更稳定</td>
</tr>
</tbody></table>
<p><strong>图解说明</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">训练过程对比：</span><br><span class="line">+---------------------+      +---------------------+</span><br><span class="line">|   情景训练流程        |      |   经典训练流程        |</span><br><span class="line">+---------------------+      +---------------------+</span><br><span class="line">|                     |      |                     |</span><br><span class="line">|  任务采样器           |      |  标准数据加载器        |</span><br><span class="line">|  (N-way K-shot)     |      |  (随机批次)           |</span><br><span class="line">|          |          |      |          |          |</span><br><span class="line">|          v          |      |          v          |</span><br><span class="line">|  模型(无分类头)       |      |  模型(带分类头)        |</span><br><span class="line">|          |          |      |          |          |</span><br><span class="line">|          v          |      |          v          |</span><br><span class="line">|  少样本分类器         |      |  交叉熵损失           |</span><br><span class="line">|  (原型网络等)         |      |          |          |</span><br><span class="line">|          |          |      |          v          |</span><br><span class="line">|          v          |      |  参数更新             |</span><br><span class="line">|  任务损失计算         |      |                     |</span><br><span class="line">|          |          |      +---------------------+</span><br><span class="line">|          v          |</span><br><span class="line">|  参数更新             |</span><br><span class="line">|                     |</span><br><span class="line">+---------------------+</span><br></pre></td></tr></table></figure>

<p><strong>总结分析</strong></p>
<ol>
<li><p><strong>哲学差异</strong>：</p>
<ul>
<li>情景训练：采用”测试即训练”的理念，直接在少样本任务形式上优化模型</li>
<li>经典训练：遵循”先学习通用特征，再适应特定任务”的分步策略</li>
</ul>
</li>
<li><p><strong>实际应用</strong>：</p>
<ul>
<li>经典训练更适合工业部署：训练简单，模型可复用</li>
<li>情景训练更适合研究探索：可直接优化少样本性能</li>
</ul>
</li>
<li><p><strong>趋势发展</strong>：</p>
<ul>
<li>早期研究（2015-2018）以情景训练为主</li>
<li>近期工作（2019至今）表明经典训练+好的特征提取器能达到可比甚至更好的效果</li>
<li>当前趋势是结合二者优势：经典训练主干网络，情景微调</li>
</ul>
</li>
<li><p><strong>选择建议：</strong></p>
<p><img src="/blog2025.github.io/2025/05/28/Ajax%20+%20axios/mermaid_20250731_bac117.png" alt="deepseek_mermaid_20250731_bac117"></p>
</li>
<li><p><strong>混合方法</strong>：<br>现代小样本学习常结合两种方法的优势：</p>
<ul>
<li>使用经典训练预训练强大的特征提取器</li>
<li>在测试时使用情景适应方法进行快速调整</li>
<li>在资源允许时进行情景微调</li>
</ul>
</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/blog2025.github.io/2025/07/01/Qt/" rel="prev" title="Qt">
                  <i class="fa fa-angle-left"></i> Qt
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2025</span>
    
    <!-- 去除心形图案
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    -->
    <span class="post-meta-divider">|</span>

    <span class="author" itemprop="copyrightHolder">lsdyun</span>
  </div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>

<!--隐藏网页底部powered by Hexo 强力驱动-->
<!--
  <div class="powered-by">由 <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/pisces/" rel="noopener" target="_blank">NexT.Pisces</a> 强力驱动
  </div>
-->

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script>
<script src="/blog2025.github.io/js/comments.js"></script><script src="/blog2025.github.io/js/utils.js"></script><script src="/blog2025.github.io/js/motion.js"></script><script src="/blog2025.github.io/js/sidebar.js"></script><script src="/blog2025.github.io/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/blog2025.github.io/js/third-party/search/local-search.js"></script>




  <script src="/blog2025.github.io/js/third-party/fancybox.js"></script>

  <script src="/blog2025.github.io/js/third-party/pace.js"></script>


  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>

<script>
var options = {
  bottom: '64px',
  right: 'unset',
  left: '32px',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();
</script>

</body>
</html>
